{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d0d4499-371e-4099-a35d-784daad611b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_model(\n",
      "  (layer1): Linear(in_features=6, out_features=128, bias=True)\n",
      "  (layer2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (layer3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Linear(in_features=6, out_features=128, bias=True)\n",
      "tensor([-0.2043, -0.2430,  0.2184, -0.2084,  0.3524, -0.2949],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor(0.3087, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "''' 실험1 '''\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class test_model(nn.Module):\n",
    "    def __init__(self, input_size, node, output_size):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_size, node)\n",
    "        self.layer2 = nn.Linear(node, node)\n",
    "        self.layer3 = nn.Linear(node, output_size)\n",
    "    def forward(self, x):\n",
    "        output = self.layer1(x)\n",
    "        output = self.layer2(x)\n",
    "        output = self.layer3(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "model = test_model(6, 128, 10)\n",
    "print(model)\n",
    "# dir(model)\n",
    "print(model.layer1)\n",
    "# dir(model.layer1)\n",
    "# print(model.layer1.weight, len(model.layer1.weight))\n",
    "print(model.layer1.weight[0])\n",
    "# print(model.layer1.bias, len(model.layer1.bias))\n",
    "print(model.layer1.bias[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab24a0ec-0911-430b-b98e-301b99edbe38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-2.0435e-01, -2.4299e-01,  2.1839e-01, -2.0843e-01,  3.5243e-01,\n",
      "         -2.9493e-01],\n",
      "        [-2.8768e-01, -3.4519e-01, -3.8701e-01,  3.4633e-02, -3.2703e-01,\n",
      "          3.5123e-01],\n",
      "        [ 7.3556e-02, -2.4462e-01,  3.3725e-01, -3.4595e-01,  1.7922e-01,\n",
      "          3.1500e-01],\n",
      "        [-5.4492e-02,  3.0055e-01,  2.8981e-01, -1.9436e-01,  3.2221e-01,\n",
      "          1.2135e-01],\n",
      "        [-3.3744e-01, -1.2235e-01, -3.1375e-02, -2.7713e-01, -3.3624e-01,\n",
      "          2.8564e-01],\n",
      "        [-2.8987e-01,  3.3379e-01,  3.9473e-01,  8.2572e-02, -1.9313e-01,\n",
      "          3.0776e-01],\n",
      "        [-3.6567e-02, -2.7647e-01,  4.0385e-01,  2.1352e-01,  3.5086e-01,\n",
      "         -6.9383e-03],\n",
      "        [-2.7240e-01, -3.7909e-01, -2.3501e-01,  2.0670e-01,  1.0524e-01,\n",
      "         -1.9582e-01],\n",
      "        [ 2.5638e-01,  1.0540e-01, -4.7960e-02,  4.3607e-02,  8.7864e-02,\n",
      "          3.2397e-01],\n",
      "        [ 7.3561e-04, -3.1597e-01,  1.7389e-01,  2.4225e-01, -1.3081e-01,\n",
      "         -4.5555e-03],\n",
      "        [ 2.1720e-01, -1.8893e-01, -3.0244e-02,  9.4818e-02,  1.8645e-01,\n",
      "         -1.5372e-01],\n",
      "        [ 3.6667e-01, -1.7195e-02,  2.0479e-01,  1.8870e-01,  3.1682e-01,\n",
      "          1.0628e-01],\n",
      "        [ 2.5034e-01, -1.0196e-01,  8.3269e-02, -3.7754e-01, -3.8272e-01,\n",
      "          2.1498e-01],\n",
      "        [-1.5811e-02,  1.6664e-01, -2.6639e-01, -2.0875e-01,  2.3037e-01,\n",
      "         -3.5859e-01],\n",
      "        [ 9.1393e-02, -1.9939e-01, -3.5078e-01, -1.1268e-01, -7.6479e-03,\n",
      "         -2.1347e-01],\n",
      "        [-1.7820e-01, -3.0528e-01,  2.8357e-02,  1.0298e-01,  9.7522e-02,\n",
      "          3.1716e-01],\n",
      "        [-2.9026e-01,  3.0755e-01, -1.6288e-01, -3.9311e-01, -1.9481e-01,\n",
      "         -8.3901e-02],\n",
      "        [-8.7342e-02, -3.7210e-01, -3.5172e-01,  3.3270e-02,  3.0392e-01,\n",
      "          3.2869e-01],\n",
      "        [-1.9997e-02, -3.5396e-02, -3.6182e-01, -9.5876e-02,  1.0560e-01,\n",
      "          2.4760e-03],\n",
      "        [-3.8534e-01,  1.8993e-01, -1.2493e-01, -7.2649e-02,  1.1542e-01,\n",
      "          1.2979e-02],\n",
      "        [-1.8533e-01, -1.1107e-01,  2.7530e-01, -4.0817e-01,  1.4975e-01,\n",
      "          1.5277e-01],\n",
      "        [ 2.9713e-01,  3.9252e-01, -3.1286e-01,  3.7513e-01,  1.1925e-01,\n",
      "         -3.2885e-01],\n",
      "        [-1.9729e-01, -1.1262e-01, -7.5289e-02, -3.6800e-01,  1.0814e-01,\n",
      "          2.3699e-01],\n",
      "        [ 4.2549e-02,  3.3474e-02,  2.7271e-02, -3.7335e-01, -7.9159e-02,\n",
      "          1.9899e-01],\n",
      "        [-2.3483e-01,  1.4576e-01, -2.0071e-01,  7.3348e-03, -3.2393e-01,\n",
      "          3.0624e-01],\n",
      "        [ 1.4286e-01,  4.1216e-02, -1.1974e-01, -2.1700e-01,  1.2523e-01,\n",
      "         -2.1377e-01],\n",
      "        [ 2.4851e-01,  3.8452e-01,  1.0379e-01,  2.5291e-01,  1.5788e-01,\n",
      "         -2.5958e-01],\n",
      "        [ 3.2943e-01,  2.3964e-01, -5.4570e-03,  1.0180e-01, -2.5913e-02,\n",
      "         -3.8560e-01],\n",
      "        [-1.7030e-01,  1.7878e-02, -3.7669e-01, -1.9563e-01, -2.0973e-01,\n",
      "          3.7438e-02],\n",
      "        [ 2.2190e-01, -3.7082e-01, -2.3671e-01, -1.1132e-01, -2.6341e-01,\n",
      "          1.3688e-01],\n",
      "        [ 3.7579e-01,  2.9216e-01,  6.9063e-02,  1.3832e-01,  1.8380e-02,\n",
      "          2.3083e-01],\n",
      "        [-2.1476e-01, -3.5846e-01,  6.7519e-02,  2.6324e-02,  1.4389e-01,\n",
      "          4.0306e-01],\n",
      "        [-2.6497e-01, -2.0213e-01, -2.0034e-01, -7.4535e-02,  4.0083e-02,\n",
      "         -1.5075e-01],\n",
      "        [-1.0616e-01,  2.2498e-02,  4.0115e-01,  2.6506e-01,  3.2552e-01,\n",
      "         -1.6035e-01],\n",
      "        [-3.3356e-01,  9.2129e-02,  3.2847e-01, -1.0525e-01,  1.1027e-01,\n",
      "         -8.3298e-02],\n",
      "        [ 1.1105e-01, -1.4401e-01, -3.9845e-01, -3.5274e-01, -1.3947e-01,\n",
      "          9.0870e-03],\n",
      "        [ 3.6815e-01,  3.0619e-01,  1.0456e-02, -1.4989e-01,  2.3013e-01,\n",
      "          3.5618e-01],\n",
      "        [ 1.9080e-01,  4.4911e-02, -2.9942e-01, -1.7247e-01,  4.4247e-02,\n",
      "         -3.4857e-01],\n",
      "        [-2.3792e-01,  1.6841e-01,  4.6476e-02,  2.3354e-01,  2.2197e-01,\n",
      "          9.7226e-02],\n",
      "        [ 1.2768e-01,  5.7313e-02, -1.3035e-01, -3.6430e-01, -1.7332e-02,\n",
      "          4.0442e-01],\n",
      "        [ 7.9486e-02,  2.8833e-01, -2.6786e-01, -3.3915e-01,  3.9866e-01,\n",
      "          1.0173e-01],\n",
      "        [-3.2224e-01,  2.9438e-01, -2.6147e-01, -2.3100e-01, -9.5930e-02,\n",
      "         -2.9863e-01],\n",
      "        [ 1.7282e-01,  3.5789e-01, -1.2194e-02,  3.0798e-01,  2.3797e-01,\n",
      "          1.8616e-01],\n",
      "        [-1.3386e-01, -2.0239e-01,  3.1993e-01,  2.3383e-01,  1.0894e-02,\n",
      "         -1.5807e-01],\n",
      "        [ 1.0083e-01, -1.2130e-01, -8.6842e-02,  1.5184e-01,  3.9446e-01,\n",
      "         -1.1663e-01],\n",
      "        [ 2.2304e-01,  3.9150e-01,  1.3044e-01,  2.2134e-01,  2.1462e-01,\n",
      "          2.7335e-01],\n",
      "        [ 3.0584e-01, -2.6923e-01,  3.5174e-01,  2.0039e-01, -1.9884e-01,\n",
      "          4.0825e-01],\n",
      "        [-3.2752e-01,  3.1369e-01,  1.1147e-01, -1.3469e-01,  3.4397e-01,\n",
      "         -1.9862e-02],\n",
      "        [-9.5751e-02, -2.9524e-01,  1.4157e-01,  3.9810e-01,  3.6921e-01,\n",
      "          2.3325e-01],\n",
      "        [ 1.5687e-01,  3.9684e-01, -3.3656e-01, -2.4727e-01,  3.5319e-01,\n",
      "         -1.9003e-01],\n",
      "        [ 3.1176e-01, -2.5600e-01, -3.3005e-02, -3.0527e-01, -3.0740e-01,\n",
      "         -1.2792e-02],\n",
      "        [ 2.2752e-01, -2.9479e-01, -1.7502e-01, -1.6488e-01, -1.2423e-01,\n",
      "          2.0741e-01],\n",
      "        [ 2.3701e-01,  1.2014e-02,  1.1502e-01, -2.5611e-01, -9.2141e-02,\n",
      "         -3.7046e-01],\n",
      "        [ 3.2821e-01,  1.3194e-01,  2.8250e-01, -2.9472e-02,  2.3931e-01,\n",
      "         -2.6822e-01],\n",
      "        [-1.6935e-01, -3.4870e-01, -1.5455e-02,  1.0899e-01,  1.4348e-01,\n",
      "         -4.0377e-01],\n",
      "        [-2.5640e-01, -2.6451e-01,  3.9567e-01,  1.3200e-01,  2.8638e-01,\n",
      "         -3.5139e-01],\n",
      "        [ 1.3520e-01, -1.2865e-01,  2.0681e-01, -3.0056e-01,  4.5700e-02,\n",
      "         -1.2522e-01],\n",
      "        [ 6.7975e-02, -3.9899e-01,  2.9944e-01, -4.4414e-02, -7.7014e-02,\n",
      "         -3.6879e-01],\n",
      "        [ 4.0504e-04, -7.3066e-02, -1.9678e-01,  9.9879e-02,  2.1063e-01,\n",
      "         -2.1800e-01],\n",
      "        [ 2.1297e-01,  1.6789e-01,  2.5200e-01,  1.7974e-01,  2.0180e-02,\n",
      "          2.2858e-01],\n",
      "        [-3.0956e-01, -8.4866e-02,  2.2169e-01, -2.7478e-01,  3.3415e-03,\n",
      "         -1.2634e-01],\n",
      "        [ 3.6666e-01,  3.5942e-01,  1.4953e-01,  5.5847e-02, -1.7511e-01,\n",
      "         -7.1261e-03],\n",
      "        [-2.6387e-01,  8.3707e-02,  7.9937e-02, -3.5273e-01, -2.9464e-01,\n",
      "         -2.8838e-02],\n",
      "        [ 4.9766e-02, -3.9025e-01, -3.4598e-01, -1.2375e-01, -5.0251e-02,\n",
      "          1.9752e-01],\n",
      "        [-2.4652e-01,  2.5212e-01,  3.8914e-01, -1.2923e-01, -5.5341e-02,\n",
      "         -2.2735e-01],\n",
      "        [-2.2131e-01,  1.6353e-01, -9.4279e-02,  2.3651e-01, -1.9696e-01,\n",
      "          1.5301e-01],\n",
      "        [ 3.8754e-01, -3.4928e-01, -2.3320e-01,  2.1714e-01, -3.4024e-01,\n",
      "         -3.1176e-01],\n",
      "        [-3.7578e-01, -2.3085e-01,  2.1602e-01,  9.3545e-02,  8.0152e-02,\n",
      "         -3.6040e-01],\n",
      "        [ 3.6516e-01, -3.1036e-02, -3.1265e-01,  2.6876e-02, -8.3932e-02,\n",
      "         -1.2022e-01],\n",
      "        [-2.8577e-01, -1.0622e-01, -3.8410e-02,  3.2543e-01, -1.9773e-01,\n",
      "          5.4844e-02],\n",
      "        [-2.3247e-01,  2.5626e-01, -3.0483e-01, -1.0634e-01,  8.3405e-02,\n",
      "          9.2892e-03],\n",
      "        [ 2.6084e-01,  1.7153e-01, -9.3019e-02,  2.0415e-01,  2.9360e-01,\n",
      "         -1.7570e-03],\n",
      "        [-2.9477e-01, -1.3766e-02, -1.5013e-01, -2.6880e-01, -3.3368e-01,\n",
      "         -1.6644e-01],\n",
      "        [ 1.6937e-01,  1.1134e-01,  8.6465e-02,  3.7427e-01, -2.4995e-01,\n",
      "         -2.7633e-01],\n",
      "        [ 3.8599e-01,  2.7349e-01, -3.8719e-01, -2.6567e-01, -2.3231e-01,\n",
      "         -3.1303e-01],\n",
      "        [ 2.0188e-01,  6.8474e-02,  3.6956e-01,  2.9379e-01,  1.4065e-01,\n",
      "         -3.6127e-01],\n",
      "        [-2.6895e-01,  3.5689e-01, -2.7417e-01,  3.2615e-01,  2.2668e-01,\n",
      "         -2.2059e-01],\n",
      "        [ 1.2347e-01,  2.6770e-01, -2.5837e-01, -9.6053e-02, -2.4013e-01,\n",
      "          2.7618e-01],\n",
      "        [ 4.7355e-02, -3.7503e-01,  3.4926e-01,  2.0287e-01,  1.6976e-02,\n",
      "         -2.3046e-01],\n",
      "        [ 1.6064e-01, -1.0585e-01, -2.9332e-01,  2.5182e-01,  1.9413e-01,\n",
      "         -3.3343e-03],\n",
      "        [-5.9715e-02,  2.6182e-01,  3.0973e-01, -7.8973e-02,  3.3814e-01,\n",
      "         -2.6610e-01],\n",
      "        [ 2.5265e-02, -2.2287e-01, -6.5652e-02,  3.0337e-01,  1.3659e-02,\n",
      "          3.1412e-02],\n",
      "        [-3.4484e-01,  2.5114e-01, -3.8833e-01, -2.6567e-01,  2.6549e-03,\n",
      "          3.3655e-01],\n",
      "        [-6.3829e-02,  1.2015e-01, -3.1386e-01,  2.8694e-01, -7.7380e-02,\n",
      "          1.1174e-01],\n",
      "        [ 3.4579e-01, -2.2063e-01, -3.8034e-01, -3.0256e-01, -1.0820e-02,\n",
      "          4.0262e-01],\n",
      "        [ 2.0713e-01,  3.6710e-01, -1.6644e-01,  3.1969e-01, -1.7733e-01,\n",
      "         -3.8171e-01],\n",
      "        [ 3.4423e-01, -2.4290e-01,  1.5601e-01, -2.0660e-02,  2.6289e-01,\n",
      "         -9.3701e-02],\n",
      "        [-1.2562e-01,  3.9818e-01, -3.0318e-01,  9.0303e-02, -3.1309e-01,\n",
      "          3.8504e-01],\n",
      "        [ 5.3883e-02, -1.2902e-02, -2.3368e-01, -6.3540e-02,  1.2826e-01,\n",
      "          4.8553e-02],\n",
      "        [ 2.0373e-01, -2.5782e-01,  9.6249e-03,  3.9744e-01,  1.2157e-01,\n",
      "         -1.4814e-01],\n",
      "        [ 2.2388e-01, -1.2114e-01, -1.8552e-01, -1.0152e-01,  2.4064e-01,\n",
      "          2.8718e-01],\n",
      "        [ 3.4154e-01, -1.8441e-01, -4.5862e-02,  1.7154e-01, -2.2046e-01,\n",
      "          3.6739e-01],\n",
      "        [ 1.7880e-01,  2.2062e-02, -5.4881e-02,  3.3819e-01, -2.7563e-01,\n",
      "         -4.2306e-03],\n",
      "        [-1.0190e-01, -2.5756e-01, -2.7949e-01,  1.7582e-01, -1.6743e-01,\n",
      "          9.2228e-02],\n",
      "        [-3.4296e-01, -2.0362e-02,  1.1449e-01, -1.3392e-01,  2.9911e-01,\n",
      "         -2.0864e-01],\n",
      "        [ 9.6955e-02,  3.9258e-01, -1.6118e-01, -3.8371e-01,  3.3173e-01,\n",
      "          3.7336e-01],\n",
      "        [-3.2490e-01, -1.6684e-01,  1.1465e-01, -1.0221e-01,  6.2397e-02,\n",
      "          1.1679e-01],\n",
      "        [ 6.2210e-02, -7.9541e-02,  3.2890e-01,  3.1208e-01,  1.2557e-02,\n",
      "         -2.1630e-02],\n",
      "        [ 1.9317e-01, -3.2557e-01,  2.5089e-01, -1.0597e-02,  3.4672e-01,\n",
      "         -1.2924e-01],\n",
      "        [ 3.5218e-01,  2.4714e-01, -1.3277e-01,  1.6322e-01, -8.8309e-02,\n",
      "         -6.8347e-02],\n",
      "        [ 2.8262e-01, -2.0986e-01, -3.3370e-01, -1.8168e-01,  9.4780e-02,\n",
      "          8.8337e-02],\n",
      "        [-8.9020e-02,  1.4777e-01, -1.2504e-01,  4.4462e-02,  2.5944e-01,\n",
      "          3.2027e-01],\n",
      "        [-3.5562e-01,  3.4249e-01,  1.3200e-01, -2.4498e-01, -9.8994e-02,\n",
      "         -1.6720e-01],\n",
      "        [ 3.8335e-02,  1.3413e-01, -2.4040e-01,  1.1078e-01, -1.6940e-02,\n",
      "          3.1445e-01],\n",
      "        [-9.5034e-02, -2.6682e-01,  3.3635e-01,  1.9198e-01,  4.2407e-02,\n",
      "          2.6793e-01],\n",
      "        [ 3.4159e-01, -7.8664e-02,  1.7316e-01, -1.1479e-01, -3.6063e-01,\n",
      "         -5.2446e-03],\n",
      "        [ 1.0139e-01, -3.8834e-01,  2.3491e-01, -3.1227e-03,  9.0729e-02,\n",
      "          1.3429e-01],\n",
      "        [-2.8341e-01, -7.4781e-02, -2.0734e-02,  3.8186e-01, -7.9376e-02,\n",
      "         -3.6705e-02],\n",
      "        [ 2.5860e-01, -2.7530e-01, -2.5483e-01,  5.7571e-03,  1.7689e-01,\n",
      "         -3.4314e-01],\n",
      "        [ 2.0845e-01,  1.9091e-04, -2.5036e-01, -2.9701e-01, -1.5267e-01,\n",
      "          3.3339e-01],\n",
      "        [-4.8620e-02, -6.9333e-02, -1.2999e-01, -3.1467e-01, -3.6236e-01,\n",
      "         -2.9782e-01],\n",
      "        [ 6.0331e-03, -2.2587e-01,  2.9366e-01, -7.6118e-02, -2.7835e-01,\n",
      "          2.6376e-01],\n",
      "        [-3.9636e-01, -1.2856e-01, -3.5296e-01, -2.1365e-01, -1.1717e-01,\n",
      "         -3.7319e-01],\n",
      "        [-3.7227e-01,  3.8361e-01,  1.2675e-01,  1.4623e-01, -4.0518e-01,\n",
      "          3.6407e-01],\n",
      "        [ 4.0462e-01, -4.4063e-02, -1.9680e-01,  6.5111e-02, -3.7494e-01,\n",
      "         -9.1401e-02],\n",
      "        [ 2.7614e-01, -1.0573e-01, -1.5548e-01,  3.7572e-01,  3.9061e-01,\n",
      "         -2.9612e-01],\n",
      "        [-2.5680e-01, -3.0770e-01,  3.9326e-01,  3.7293e-01, -3.3893e-01,\n",
      "         -2.1718e-01],\n",
      "        [-1.4504e-01,  3.8145e-01, -7.5686e-02,  1.9456e-01,  3.6883e-01,\n",
      "          3.0466e-01],\n",
      "        [-3.0368e-01,  3.7699e-01,  1.6648e-01,  1.9598e-01, -3.4158e-01,\n",
      "         -8.3203e-02],\n",
      "        [ 2.1545e-02,  9.7044e-02,  4.0105e-01, -2.6308e-01, -2.3010e-01,\n",
      "         -1.6179e-01],\n",
      "        [-4.9810e-02,  2.5784e-01, -1.3720e-01,  2.1425e-01,  3.8166e-01,\n",
      "          3.3938e-01],\n",
      "        [ 2.8269e-02, -6.6750e-02,  2.2452e-02,  2.7585e-01, -2.8722e-01,\n",
      "         -3.6824e-01],\n",
      "        [ 2.6721e-01,  3.5954e-01,  2.6263e-01, -2.9317e-01,  1.4197e-01,\n",
      "         -3.9015e-02],\n",
      "        [ 1.8449e-01,  3.0306e-01, -3.5680e-01,  2.5045e-01,  7.6895e-02,\n",
      "         -3.4740e-01],\n",
      "        [ 1.8922e-01, -2.5703e-02, -3.2425e-01, -1.1154e-01,  1.2412e-01,\n",
      "         -3.4335e-01],\n",
      "        [-3.0704e-01,  2.0230e-01, -1.5287e-01, -2.3247e-01,  8.9217e-02,\n",
      "          3.2061e-01],\n",
      "        [-2.2531e-01, -3.4969e-01,  1.3776e-01, -2.8722e-01,  1.7449e-01,\n",
      "         -9.7320e-02],\n",
      "        [-4.0925e-02, -3.7758e-01,  5.5676e-02, -1.3633e-01, -2.2538e-01,\n",
      "         -3.0505e-01]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.3087, -0.3307, -0.1191, -0.0365, -0.1780,  0.2779,  0.0928,  0.1439,\n",
      "        -0.2016, -0.1269, -0.2183, -0.0138,  0.3483, -0.2469,  0.0439,  0.3699,\n",
      "         0.2148, -0.1362, -0.0707,  0.0422,  0.3392,  0.1248,  0.3756, -0.1567,\n",
      "         0.3538,  0.0838, -0.1581,  0.2883,  0.2015,  0.2441, -0.1887, -0.2199,\n",
      "        -0.2172, -0.1533,  0.1831,  0.2498, -0.3656, -0.0677, -0.3389,  0.2042,\n",
      "        -0.3311,  0.1221, -0.3848,  0.0110,  0.0562, -0.2984,  0.1504, -0.0044,\n",
      "         0.0227,  0.0664, -0.1300,  0.3894,  0.2823,  0.1754, -0.3246, -0.0959,\n",
      "        -0.1203,  0.1674, -0.1852,  0.0456,  0.2611, -0.3733,  0.3977,  0.2596,\n",
      "        -0.1129,  0.1885, -0.0947,  0.3867,  0.3382, -0.1700,  0.3395,  0.3471,\n",
      "        -0.3453, -0.3703,  0.2338, -0.0494,  0.3718, -0.0373, -0.0283,  0.1574,\n",
      "        -0.0350,  0.0964,  0.1319, -0.0499,  0.1792, -0.3229, -0.4012, -0.2731,\n",
      "         0.1872,  0.0528,  0.2942, -0.2823,  0.2123,  0.1362, -0.1744,  0.1938,\n",
      "         0.0650, -0.3811, -0.3134,  0.1297,  0.1487,  0.0580,  0.3589, -0.3000,\n",
      "        -0.2939,  0.1117,  0.3785,  0.2231, -0.0503, -0.3116,  0.2185, -0.4022,\n",
      "         0.1611, -0.2525,  0.0176,  0.1282, -0.2159,  0.0622,  0.3196, -0.3990,\n",
      "        -0.0449, -0.1535, -0.2189, -0.0762, -0.3038, -0.1495, -0.3180,  0.2693],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 2.5196e-02, -5.0262e-02, -9.6395e-03,  ...,  5.4717e-05,\n",
      "          4.5073e-02,  4.7373e-02],\n",
      "        [-7.5594e-02,  7.2166e-02,  1.0498e-02,  ..., -5.2750e-02,\n",
      "          4.0252e-02,  7.6239e-02],\n",
      "        [-8.6519e-02,  3.7553e-02, -8.4199e-02,  ..., -4.5310e-02,\n",
      "          6.3556e-02,  1.2138e-02],\n",
      "        ...,\n",
      "        [-4.0289e-02, -5.8584e-02,  6.4241e-02,  ..., -6.2267e-03,\n",
      "          1.9191e-02,  3.1565e-02],\n",
      "        [-2.3340e-02, -3.0793e-02,  3.2091e-02,  ...,  5.6680e-02,\n",
      "          3.7316e-02, -4.2915e-02],\n",
      "        [ 3.4399e-02,  1.9080e-02, -3.9210e-02,  ..., -4.5192e-02,\n",
      "         -1.9051e-02,  6.4822e-03]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0798, -0.0358, -0.0584,  0.0243,  0.0787, -0.0727,  0.0093,  0.0346,\n",
      "        -0.0852,  0.0043,  0.0483, -0.0817, -0.0776,  0.0316, -0.0101, -0.0360,\n",
      "         0.0745, -0.0477, -0.0718, -0.0260, -0.0691,  0.0662, -0.0163, -0.0809,\n",
      "         0.0501,  0.0794, -0.0827,  0.0561, -0.0037,  0.0693, -0.0426, -0.0812,\n",
      "        -0.0712,  0.0846, -0.0801,  0.0540, -0.0729,  0.0651,  0.0173, -0.0279,\n",
      "         0.0279, -0.0393, -0.0290, -0.0470, -0.0176,  0.0825,  0.0291,  0.0645,\n",
      "         0.0084, -0.0127,  0.0295, -0.0413, -0.0724, -0.0420, -0.0140,  0.0370,\n",
      "        -0.0208,  0.0602, -0.0183,  0.0442, -0.0644, -0.0460,  0.0170, -0.0296,\n",
      "         0.0712,  0.0253, -0.0289,  0.0207, -0.0818, -0.0183,  0.0374,  0.0554,\n",
      "        -0.0700, -0.0190, -0.0565, -0.0456, -0.0277, -0.0135,  0.0483, -0.0227,\n",
      "         0.0207,  0.0636,  0.0624, -0.0176,  0.0177,  0.0461, -0.0426,  0.0156,\n",
      "         0.0463,  0.0522,  0.0419, -0.0134, -0.0149,  0.0709,  0.0665,  0.0408,\n",
      "        -0.0854, -0.0537,  0.0253,  0.0777, -0.0041, -0.0043,  0.0702, -0.0257,\n",
      "        -0.0755,  0.0757,  0.0590,  0.0385, -0.0412,  0.0567,  0.0481,  0.0169,\n",
      "        -0.0081, -0.0710, -0.0567, -0.0530, -0.0206, -0.0763, -0.0619, -0.0259,\n",
      "        -0.0818,  0.0705, -0.0276, -0.0640, -0.0485,  0.0031, -0.0220, -0.0132],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0021, -0.0646, -0.0158,  ...,  0.0490, -0.0525,  0.0869],\n",
      "        [ 0.0798, -0.0367, -0.0009,  ...,  0.0596, -0.0253, -0.0437],\n",
      "        [-0.0480, -0.0108,  0.0226,  ..., -0.0677, -0.0542, -0.0751],\n",
      "        ...,\n",
      "        [-0.0434,  0.0648, -0.0695,  ..., -0.0521,  0.0477, -0.0615],\n",
      "        [ 0.0880,  0.0876,  0.0245,  ..., -0.0267, -0.0790, -0.0298],\n",
      "        [-0.0422,  0.0456,  0.0185,  ...,  0.0303,  0.0421, -0.0746]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0032,  0.0624, -0.0221,  0.0855,  0.0016, -0.0430,  0.0768,  0.0350,\n",
      "         0.0275,  0.0847], requires_grad=True)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6, None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' 실험2 '''\n",
    "len(list(model.parameters())), print(list(model.parameters()))\n",
    "# model.layer1.weight[0][0] = 0.0792"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ff99cd1-7977-456d-bc4b-51c4c7400a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.2043)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0997)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' 실험3 '''\n",
    "print(model.state_dict()[\"layer1.weight\"][0][0])\n",
    "model.state_dict()[\"layer1.weight\"][0][0].copy_(0.0997) # 이걸 사용하면 torch.nn을 사용하여 작성한 모델도 그것의 매개변수들을 유전(진화) 알고리즘으로 다룰 수 있게 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d3cd84e-594d-4b1c-bd6b-dd9265a5c032",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0997, -0.2430,  0.2184, -0.2084,  0.3524, -0.2949]),\n",
       " OrderedDict([('layer1.weight',\n",
       "               tensor([[ 9.9700e-02, -2.4299e-01,  2.1839e-01, -2.0843e-01,  3.5243e-01,\n",
       "                        -2.9493e-01],\n",
       "                       [-2.8768e-01, -3.4519e-01, -3.8701e-01,  3.4633e-02, -3.2703e-01,\n",
       "                         3.5123e-01],\n",
       "                       [ 7.3556e-02, -2.4462e-01,  3.3725e-01, -3.4595e-01,  1.7922e-01,\n",
       "                         3.1500e-01],\n",
       "                       [-5.4492e-02,  3.0055e-01,  2.8981e-01, -1.9436e-01,  3.2221e-01,\n",
       "                         1.2135e-01],\n",
       "                       [-3.3744e-01, -1.2235e-01, -3.1375e-02, -2.7713e-01, -3.3624e-01,\n",
       "                         2.8564e-01],\n",
       "                       [-2.8987e-01,  3.3379e-01,  3.9473e-01,  8.2572e-02, -1.9313e-01,\n",
       "                         3.0776e-01],\n",
       "                       [-3.6567e-02, -2.7647e-01,  4.0385e-01,  2.1352e-01,  3.5086e-01,\n",
       "                        -6.9383e-03],\n",
       "                       [-2.7240e-01, -3.7909e-01, -2.3501e-01,  2.0670e-01,  1.0524e-01,\n",
       "                        -1.9582e-01],\n",
       "                       [ 2.5638e-01,  1.0540e-01, -4.7960e-02,  4.3607e-02,  8.7864e-02,\n",
       "                         3.2397e-01],\n",
       "                       [ 7.3561e-04, -3.1597e-01,  1.7389e-01,  2.4225e-01, -1.3081e-01,\n",
       "                        -4.5555e-03],\n",
       "                       [ 2.1720e-01, -1.8893e-01, -3.0244e-02,  9.4818e-02,  1.8645e-01,\n",
       "                        -1.5372e-01],\n",
       "                       [ 3.6667e-01, -1.7195e-02,  2.0479e-01,  1.8870e-01,  3.1682e-01,\n",
       "                         1.0628e-01],\n",
       "                       [ 2.5034e-01, -1.0196e-01,  8.3269e-02, -3.7754e-01, -3.8272e-01,\n",
       "                         2.1498e-01],\n",
       "                       [-1.5811e-02,  1.6664e-01, -2.6639e-01, -2.0875e-01,  2.3037e-01,\n",
       "                        -3.5859e-01],\n",
       "                       [ 9.1393e-02, -1.9939e-01, -3.5078e-01, -1.1268e-01, -7.6479e-03,\n",
       "                        -2.1347e-01],\n",
       "                       [-1.7820e-01, -3.0528e-01,  2.8357e-02,  1.0298e-01,  9.7522e-02,\n",
       "                         3.1716e-01],\n",
       "                       [-2.9026e-01,  3.0755e-01, -1.6288e-01, -3.9311e-01, -1.9481e-01,\n",
       "                        -8.3901e-02],\n",
       "                       [-8.7342e-02, -3.7210e-01, -3.5172e-01,  3.3270e-02,  3.0392e-01,\n",
       "                         3.2869e-01],\n",
       "                       [-1.9997e-02, -3.5396e-02, -3.6182e-01, -9.5876e-02,  1.0560e-01,\n",
       "                         2.4760e-03],\n",
       "                       [-3.8534e-01,  1.8993e-01, -1.2493e-01, -7.2649e-02,  1.1542e-01,\n",
       "                         1.2979e-02],\n",
       "                       [-1.8533e-01, -1.1107e-01,  2.7530e-01, -4.0817e-01,  1.4975e-01,\n",
       "                         1.5277e-01],\n",
       "                       [ 2.9713e-01,  3.9252e-01, -3.1286e-01,  3.7513e-01,  1.1925e-01,\n",
       "                        -3.2885e-01],\n",
       "                       [-1.9729e-01, -1.1262e-01, -7.5289e-02, -3.6800e-01,  1.0814e-01,\n",
       "                         2.3699e-01],\n",
       "                       [ 4.2549e-02,  3.3474e-02,  2.7271e-02, -3.7335e-01, -7.9159e-02,\n",
       "                         1.9899e-01],\n",
       "                       [-2.3483e-01,  1.4576e-01, -2.0071e-01,  7.3348e-03, -3.2393e-01,\n",
       "                         3.0624e-01],\n",
       "                       [ 1.4286e-01,  4.1216e-02, -1.1974e-01, -2.1700e-01,  1.2523e-01,\n",
       "                        -2.1377e-01],\n",
       "                       [ 2.4851e-01,  3.8452e-01,  1.0379e-01,  2.5291e-01,  1.5788e-01,\n",
       "                        -2.5958e-01],\n",
       "                       [ 3.2943e-01,  2.3964e-01, -5.4570e-03,  1.0180e-01, -2.5913e-02,\n",
       "                        -3.8560e-01],\n",
       "                       [-1.7030e-01,  1.7878e-02, -3.7669e-01, -1.9563e-01, -2.0973e-01,\n",
       "                         3.7438e-02],\n",
       "                       [ 2.2190e-01, -3.7082e-01, -2.3671e-01, -1.1132e-01, -2.6341e-01,\n",
       "                         1.3688e-01],\n",
       "                       [ 3.7579e-01,  2.9216e-01,  6.9063e-02,  1.3832e-01,  1.8380e-02,\n",
       "                         2.3083e-01],\n",
       "                       [-2.1476e-01, -3.5846e-01,  6.7519e-02,  2.6324e-02,  1.4389e-01,\n",
       "                         4.0306e-01],\n",
       "                       [-2.6497e-01, -2.0213e-01, -2.0034e-01, -7.4535e-02,  4.0083e-02,\n",
       "                        -1.5075e-01],\n",
       "                       [-1.0616e-01,  2.2498e-02,  4.0115e-01,  2.6506e-01,  3.2552e-01,\n",
       "                        -1.6035e-01],\n",
       "                       [-3.3356e-01,  9.2129e-02,  3.2847e-01, -1.0525e-01,  1.1027e-01,\n",
       "                        -8.3298e-02],\n",
       "                       [ 1.1105e-01, -1.4401e-01, -3.9845e-01, -3.5274e-01, -1.3947e-01,\n",
       "                         9.0870e-03],\n",
       "                       [ 3.6815e-01,  3.0619e-01,  1.0456e-02, -1.4989e-01,  2.3013e-01,\n",
       "                         3.5618e-01],\n",
       "                       [ 1.9080e-01,  4.4911e-02, -2.9942e-01, -1.7247e-01,  4.4247e-02,\n",
       "                        -3.4857e-01],\n",
       "                       [-2.3792e-01,  1.6841e-01,  4.6476e-02,  2.3354e-01,  2.2197e-01,\n",
       "                         9.7226e-02],\n",
       "                       [ 1.2768e-01,  5.7313e-02, -1.3035e-01, -3.6430e-01, -1.7332e-02,\n",
       "                         4.0442e-01],\n",
       "                       [ 7.9486e-02,  2.8833e-01, -2.6786e-01, -3.3915e-01,  3.9866e-01,\n",
       "                         1.0173e-01],\n",
       "                       [-3.2224e-01,  2.9438e-01, -2.6147e-01, -2.3100e-01, -9.5930e-02,\n",
       "                        -2.9863e-01],\n",
       "                       [ 1.7282e-01,  3.5789e-01, -1.2194e-02,  3.0798e-01,  2.3797e-01,\n",
       "                         1.8616e-01],\n",
       "                       [-1.3386e-01, -2.0239e-01,  3.1993e-01,  2.3383e-01,  1.0894e-02,\n",
       "                        -1.5807e-01],\n",
       "                       [ 1.0083e-01, -1.2130e-01, -8.6842e-02,  1.5184e-01,  3.9446e-01,\n",
       "                        -1.1663e-01],\n",
       "                       [ 2.2304e-01,  3.9150e-01,  1.3044e-01,  2.2134e-01,  2.1462e-01,\n",
       "                         2.7335e-01],\n",
       "                       [ 3.0584e-01, -2.6923e-01,  3.5174e-01,  2.0039e-01, -1.9884e-01,\n",
       "                         4.0825e-01],\n",
       "                       [-3.2752e-01,  3.1369e-01,  1.1147e-01, -1.3469e-01,  3.4397e-01,\n",
       "                        -1.9862e-02],\n",
       "                       [-9.5751e-02, -2.9524e-01,  1.4157e-01,  3.9810e-01,  3.6921e-01,\n",
       "                         2.3325e-01],\n",
       "                       [ 1.5687e-01,  3.9684e-01, -3.3656e-01, -2.4727e-01,  3.5319e-01,\n",
       "                        -1.9003e-01],\n",
       "                       [ 3.1176e-01, -2.5600e-01, -3.3005e-02, -3.0527e-01, -3.0740e-01,\n",
       "                        -1.2792e-02],\n",
       "                       [ 2.2752e-01, -2.9479e-01, -1.7502e-01, -1.6488e-01, -1.2423e-01,\n",
       "                         2.0741e-01],\n",
       "                       [ 2.3701e-01,  1.2014e-02,  1.1502e-01, -2.5611e-01, -9.2141e-02,\n",
       "                        -3.7046e-01],\n",
       "                       [ 3.2821e-01,  1.3194e-01,  2.8250e-01, -2.9472e-02,  2.3931e-01,\n",
       "                        -2.6822e-01],\n",
       "                       [-1.6935e-01, -3.4870e-01, -1.5455e-02,  1.0899e-01,  1.4348e-01,\n",
       "                        -4.0377e-01],\n",
       "                       [-2.5640e-01, -2.6451e-01,  3.9567e-01,  1.3200e-01,  2.8638e-01,\n",
       "                        -3.5139e-01],\n",
       "                       [ 1.3520e-01, -1.2865e-01,  2.0681e-01, -3.0056e-01,  4.5700e-02,\n",
       "                        -1.2522e-01],\n",
       "                       [ 6.7975e-02, -3.9899e-01,  2.9944e-01, -4.4414e-02, -7.7014e-02,\n",
       "                        -3.6879e-01],\n",
       "                       [ 4.0504e-04, -7.3066e-02, -1.9678e-01,  9.9879e-02,  2.1063e-01,\n",
       "                        -2.1800e-01],\n",
       "                       [ 2.1297e-01,  1.6789e-01,  2.5200e-01,  1.7974e-01,  2.0180e-02,\n",
       "                         2.2858e-01],\n",
       "                       [-3.0956e-01, -8.4866e-02,  2.2169e-01, -2.7478e-01,  3.3415e-03,\n",
       "                        -1.2634e-01],\n",
       "                       [ 3.6666e-01,  3.5942e-01,  1.4953e-01,  5.5847e-02, -1.7511e-01,\n",
       "                        -7.1261e-03],\n",
       "                       [-2.6387e-01,  8.3707e-02,  7.9937e-02, -3.5273e-01, -2.9464e-01,\n",
       "                        -2.8838e-02],\n",
       "                       [ 4.9766e-02, -3.9025e-01, -3.4598e-01, -1.2375e-01, -5.0251e-02,\n",
       "                         1.9752e-01],\n",
       "                       [-2.4652e-01,  2.5212e-01,  3.8914e-01, -1.2923e-01, -5.5341e-02,\n",
       "                        -2.2735e-01],\n",
       "                       [-2.2131e-01,  1.6353e-01, -9.4279e-02,  2.3651e-01, -1.9696e-01,\n",
       "                         1.5301e-01],\n",
       "                       [ 3.8754e-01, -3.4928e-01, -2.3320e-01,  2.1714e-01, -3.4024e-01,\n",
       "                        -3.1176e-01],\n",
       "                       [-3.7578e-01, -2.3085e-01,  2.1602e-01,  9.3545e-02,  8.0152e-02,\n",
       "                        -3.6040e-01],\n",
       "                       [ 3.6516e-01, -3.1036e-02, -3.1265e-01,  2.6876e-02, -8.3932e-02,\n",
       "                        -1.2022e-01],\n",
       "                       [-2.8577e-01, -1.0622e-01, -3.8410e-02,  3.2543e-01, -1.9773e-01,\n",
       "                         5.4844e-02],\n",
       "                       [-2.3247e-01,  2.5626e-01, -3.0483e-01, -1.0634e-01,  8.3405e-02,\n",
       "                         9.2892e-03],\n",
       "                       [ 2.6084e-01,  1.7153e-01, -9.3019e-02,  2.0415e-01,  2.9360e-01,\n",
       "                        -1.7570e-03],\n",
       "                       [-2.9477e-01, -1.3766e-02, -1.5013e-01, -2.6880e-01, -3.3368e-01,\n",
       "                        -1.6644e-01],\n",
       "                       [ 1.6937e-01,  1.1134e-01,  8.6465e-02,  3.7427e-01, -2.4995e-01,\n",
       "                        -2.7633e-01],\n",
       "                       [ 3.8599e-01,  2.7349e-01, -3.8719e-01, -2.6567e-01, -2.3231e-01,\n",
       "                        -3.1303e-01],\n",
       "                       [ 2.0188e-01,  6.8474e-02,  3.6956e-01,  2.9379e-01,  1.4065e-01,\n",
       "                        -3.6127e-01],\n",
       "                       [-2.6895e-01,  3.5689e-01, -2.7417e-01,  3.2615e-01,  2.2668e-01,\n",
       "                        -2.2059e-01],\n",
       "                       [ 1.2347e-01,  2.6770e-01, -2.5837e-01, -9.6053e-02, -2.4013e-01,\n",
       "                         2.7618e-01],\n",
       "                       [ 4.7355e-02, -3.7503e-01,  3.4926e-01,  2.0287e-01,  1.6976e-02,\n",
       "                        -2.3046e-01],\n",
       "                       [ 1.6064e-01, -1.0585e-01, -2.9332e-01,  2.5182e-01,  1.9413e-01,\n",
       "                        -3.3343e-03],\n",
       "                       [-5.9715e-02,  2.6182e-01,  3.0973e-01, -7.8973e-02,  3.3814e-01,\n",
       "                        -2.6610e-01],\n",
       "                       [ 2.5265e-02, -2.2287e-01, -6.5652e-02,  3.0337e-01,  1.3659e-02,\n",
       "                         3.1412e-02],\n",
       "                       [-3.4484e-01,  2.5114e-01, -3.8833e-01, -2.6567e-01,  2.6549e-03,\n",
       "                         3.3655e-01],\n",
       "                       [-6.3829e-02,  1.2015e-01, -3.1386e-01,  2.8694e-01, -7.7380e-02,\n",
       "                         1.1174e-01],\n",
       "                       [ 3.4579e-01, -2.2063e-01, -3.8034e-01, -3.0256e-01, -1.0820e-02,\n",
       "                         4.0262e-01],\n",
       "                       [ 2.0713e-01,  3.6710e-01, -1.6644e-01,  3.1969e-01, -1.7733e-01,\n",
       "                        -3.8171e-01],\n",
       "                       [ 3.4423e-01, -2.4290e-01,  1.5601e-01, -2.0660e-02,  2.6289e-01,\n",
       "                        -9.3701e-02],\n",
       "                       [-1.2562e-01,  3.9818e-01, -3.0318e-01,  9.0303e-02, -3.1309e-01,\n",
       "                         3.8504e-01],\n",
       "                       [ 5.3883e-02, -1.2902e-02, -2.3368e-01, -6.3540e-02,  1.2826e-01,\n",
       "                         4.8553e-02],\n",
       "                       [ 2.0373e-01, -2.5782e-01,  9.6249e-03,  3.9744e-01,  1.2157e-01,\n",
       "                        -1.4814e-01],\n",
       "                       [ 2.2388e-01, -1.2114e-01, -1.8552e-01, -1.0152e-01,  2.4064e-01,\n",
       "                         2.8718e-01],\n",
       "                       [ 3.4154e-01, -1.8441e-01, -4.5862e-02,  1.7154e-01, -2.2046e-01,\n",
       "                         3.6739e-01],\n",
       "                       [ 1.7880e-01,  2.2062e-02, -5.4881e-02,  3.3819e-01, -2.7563e-01,\n",
       "                        -4.2306e-03],\n",
       "                       [-1.0190e-01, -2.5756e-01, -2.7949e-01,  1.7582e-01, -1.6743e-01,\n",
       "                         9.2228e-02],\n",
       "                       [-3.4296e-01, -2.0362e-02,  1.1449e-01, -1.3392e-01,  2.9911e-01,\n",
       "                        -2.0864e-01],\n",
       "                       [ 9.6955e-02,  3.9258e-01, -1.6118e-01, -3.8371e-01,  3.3173e-01,\n",
       "                         3.7336e-01],\n",
       "                       [-3.2490e-01, -1.6684e-01,  1.1465e-01, -1.0221e-01,  6.2397e-02,\n",
       "                         1.1679e-01],\n",
       "                       [ 6.2210e-02, -7.9541e-02,  3.2890e-01,  3.1208e-01,  1.2557e-02,\n",
       "                        -2.1630e-02],\n",
       "                       [ 1.9317e-01, -3.2557e-01,  2.5089e-01, -1.0597e-02,  3.4672e-01,\n",
       "                        -1.2924e-01],\n",
       "                       [ 3.5218e-01,  2.4714e-01, -1.3277e-01,  1.6322e-01, -8.8309e-02,\n",
       "                        -6.8347e-02],\n",
       "                       [ 2.8262e-01, -2.0986e-01, -3.3370e-01, -1.8168e-01,  9.4780e-02,\n",
       "                         8.8337e-02],\n",
       "                       [-8.9020e-02,  1.4777e-01, -1.2504e-01,  4.4462e-02,  2.5944e-01,\n",
       "                         3.2027e-01],\n",
       "                       [-3.5562e-01,  3.4249e-01,  1.3200e-01, -2.4498e-01, -9.8994e-02,\n",
       "                        -1.6720e-01],\n",
       "                       [ 3.8335e-02,  1.3413e-01, -2.4040e-01,  1.1078e-01, -1.6940e-02,\n",
       "                         3.1445e-01],\n",
       "                       [-9.5034e-02, -2.6682e-01,  3.3635e-01,  1.9198e-01,  4.2407e-02,\n",
       "                         2.6793e-01],\n",
       "                       [ 3.4159e-01, -7.8664e-02,  1.7316e-01, -1.1479e-01, -3.6063e-01,\n",
       "                        -5.2446e-03],\n",
       "                       [ 1.0139e-01, -3.8834e-01,  2.3491e-01, -3.1227e-03,  9.0729e-02,\n",
       "                         1.3429e-01],\n",
       "                       [-2.8341e-01, -7.4781e-02, -2.0734e-02,  3.8186e-01, -7.9376e-02,\n",
       "                        -3.6705e-02],\n",
       "                       [ 2.5860e-01, -2.7530e-01, -2.5483e-01,  5.7571e-03,  1.7689e-01,\n",
       "                        -3.4314e-01],\n",
       "                       [ 2.0845e-01,  1.9091e-04, -2.5036e-01, -2.9701e-01, -1.5267e-01,\n",
       "                         3.3339e-01],\n",
       "                       [-4.8620e-02, -6.9333e-02, -1.2999e-01, -3.1467e-01, -3.6236e-01,\n",
       "                        -2.9782e-01],\n",
       "                       [ 6.0331e-03, -2.2587e-01,  2.9366e-01, -7.6118e-02, -2.7835e-01,\n",
       "                         2.6376e-01],\n",
       "                       [-3.9636e-01, -1.2856e-01, -3.5296e-01, -2.1365e-01, -1.1717e-01,\n",
       "                        -3.7319e-01],\n",
       "                       [-3.7227e-01,  3.8361e-01,  1.2675e-01,  1.4623e-01, -4.0518e-01,\n",
       "                         3.6407e-01],\n",
       "                       [ 4.0462e-01, -4.4063e-02, -1.9680e-01,  6.5111e-02, -3.7494e-01,\n",
       "                        -9.1401e-02],\n",
       "                       [ 2.7614e-01, -1.0573e-01, -1.5548e-01,  3.7572e-01,  3.9061e-01,\n",
       "                        -2.9612e-01],\n",
       "                       [-2.5680e-01, -3.0770e-01,  3.9326e-01,  3.7293e-01, -3.3893e-01,\n",
       "                        -2.1718e-01],\n",
       "                       [-1.4504e-01,  3.8145e-01, -7.5686e-02,  1.9456e-01,  3.6883e-01,\n",
       "                         3.0466e-01],\n",
       "                       [-3.0368e-01,  3.7699e-01,  1.6648e-01,  1.9598e-01, -3.4158e-01,\n",
       "                        -8.3203e-02],\n",
       "                       [ 2.1545e-02,  9.7044e-02,  4.0105e-01, -2.6308e-01, -2.3010e-01,\n",
       "                        -1.6179e-01],\n",
       "                       [-4.9810e-02,  2.5784e-01, -1.3720e-01,  2.1425e-01,  3.8166e-01,\n",
       "                         3.3938e-01],\n",
       "                       [ 2.8269e-02, -6.6750e-02,  2.2452e-02,  2.7585e-01, -2.8722e-01,\n",
       "                        -3.6824e-01],\n",
       "                       [ 2.6721e-01,  3.5954e-01,  2.6263e-01, -2.9317e-01,  1.4197e-01,\n",
       "                        -3.9015e-02],\n",
       "                       [ 1.8449e-01,  3.0306e-01, -3.5680e-01,  2.5045e-01,  7.6895e-02,\n",
       "                        -3.4740e-01],\n",
       "                       [ 1.8922e-01, -2.5703e-02, -3.2425e-01, -1.1154e-01,  1.2412e-01,\n",
       "                        -3.4335e-01],\n",
       "                       [-3.0704e-01,  2.0230e-01, -1.5287e-01, -2.3247e-01,  8.9217e-02,\n",
       "                         3.2061e-01],\n",
       "                       [-2.2531e-01, -3.4969e-01,  1.3776e-01, -2.8722e-01,  1.7449e-01,\n",
       "                        -9.7320e-02],\n",
       "                       [-4.0925e-02, -3.7758e-01,  5.5676e-02, -1.3633e-01, -2.2538e-01,\n",
       "                        -3.0505e-01]])),\n",
       "              ('layer1.bias',\n",
       "               tensor([ 0.3087, -0.3307, -0.1191, -0.0365, -0.1780,  0.2779,  0.0928,  0.1439,\n",
       "                       -0.2016, -0.1269, -0.2183, -0.0138,  0.3483, -0.2469,  0.0439,  0.3699,\n",
       "                        0.2148, -0.1362, -0.0707,  0.0422,  0.3392,  0.1248,  0.3756, -0.1567,\n",
       "                        0.3538,  0.0838, -0.1581,  0.2883,  0.2015,  0.2441, -0.1887, -0.2199,\n",
       "                       -0.2172, -0.1533,  0.1831,  0.2498, -0.3656, -0.0677, -0.3389,  0.2042,\n",
       "                       -0.3311,  0.1221, -0.3848,  0.0110,  0.0562, -0.2984,  0.1504, -0.0044,\n",
       "                        0.0227,  0.0664, -0.1300,  0.3894,  0.2823,  0.1754, -0.3246, -0.0959,\n",
       "                       -0.1203,  0.1674, -0.1852,  0.0456,  0.2611, -0.3733,  0.3977,  0.2596,\n",
       "                       -0.1129,  0.1885, -0.0947,  0.3867,  0.3382, -0.1700,  0.3395,  0.3471,\n",
       "                       -0.3453, -0.3703,  0.2338, -0.0494,  0.3718, -0.0373, -0.0283,  0.1574,\n",
       "                       -0.0350,  0.0964,  0.1319, -0.0499,  0.1792, -0.3229, -0.4012, -0.2731,\n",
       "                        0.1872,  0.0528,  0.2942, -0.2823,  0.2123,  0.1362, -0.1744,  0.1938,\n",
       "                        0.0650, -0.3811, -0.3134,  0.1297,  0.1487,  0.0580,  0.3589, -0.3000,\n",
       "                       -0.2939,  0.1117,  0.3785,  0.2231, -0.0503, -0.3116,  0.2185, -0.4022,\n",
       "                        0.1611, -0.2525,  0.0176,  0.1282, -0.2159,  0.0622,  0.3196, -0.3990,\n",
       "                       -0.0449, -0.1535, -0.2189, -0.0762, -0.3038, -0.1495, -0.3180,  0.2693])),\n",
       "              ('layer2.weight',\n",
       "               tensor([[ 2.5196e-02, -5.0262e-02, -9.6395e-03,  ...,  5.4717e-05,\n",
       "                         4.5073e-02,  4.7373e-02],\n",
       "                       [-7.5594e-02,  7.2166e-02,  1.0498e-02,  ..., -5.2750e-02,\n",
       "                         4.0252e-02,  7.6239e-02],\n",
       "                       [-8.6519e-02,  3.7553e-02, -8.4199e-02,  ..., -4.5310e-02,\n",
       "                         6.3556e-02,  1.2138e-02],\n",
       "                       ...,\n",
       "                       [-4.0289e-02, -5.8584e-02,  6.4241e-02,  ..., -6.2267e-03,\n",
       "                         1.9191e-02,  3.1565e-02],\n",
       "                       [-2.3340e-02, -3.0793e-02,  3.2091e-02,  ...,  5.6680e-02,\n",
       "                         3.7316e-02, -4.2915e-02],\n",
       "                       [ 3.4399e-02,  1.9080e-02, -3.9210e-02,  ..., -4.5192e-02,\n",
       "                        -1.9051e-02,  6.4822e-03]])),\n",
       "              ('layer2.bias',\n",
       "               tensor([ 0.0798, -0.0358, -0.0584,  0.0243,  0.0787, -0.0727,  0.0093,  0.0346,\n",
       "                       -0.0852,  0.0043,  0.0483, -0.0817, -0.0776,  0.0316, -0.0101, -0.0360,\n",
       "                        0.0745, -0.0477, -0.0718, -0.0260, -0.0691,  0.0662, -0.0163, -0.0809,\n",
       "                        0.0501,  0.0794, -0.0827,  0.0561, -0.0037,  0.0693, -0.0426, -0.0812,\n",
       "                       -0.0712,  0.0846, -0.0801,  0.0540, -0.0729,  0.0651,  0.0173, -0.0279,\n",
       "                        0.0279, -0.0393, -0.0290, -0.0470, -0.0176,  0.0825,  0.0291,  0.0645,\n",
       "                        0.0084, -0.0127,  0.0295, -0.0413, -0.0724, -0.0420, -0.0140,  0.0370,\n",
       "                       -0.0208,  0.0602, -0.0183,  0.0442, -0.0644, -0.0460,  0.0170, -0.0296,\n",
       "                        0.0712,  0.0253, -0.0289,  0.0207, -0.0818, -0.0183,  0.0374,  0.0554,\n",
       "                       -0.0700, -0.0190, -0.0565, -0.0456, -0.0277, -0.0135,  0.0483, -0.0227,\n",
       "                        0.0207,  0.0636,  0.0624, -0.0176,  0.0177,  0.0461, -0.0426,  0.0156,\n",
       "                        0.0463,  0.0522,  0.0419, -0.0134, -0.0149,  0.0709,  0.0665,  0.0408,\n",
       "                       -0.0854, -0.0537,  0.0253,  0.0777, -0.0041, -0.0043,  0.0702, -0.0257,\n",
       "                       -0.0755,  0.0757,  0.0590,  0.0385, -0.0412,  0.0567,  0.0481,  0.0169,\n",
       "                       -0.0081, -0.0710, -0.0567, -0.0530, -0.0206, -0.0763, -0.0619, -0.0259,\n",
       "                       -0.0818,  0.0705, -0.0276, -0.0640, -0.0485,  0.0031, -0.0220, -0.0132])),\n",
       "              ('layer3.weight',\n",
       "               tensor([[-0.0021, -0.0646, -0.0158,  ...,  0.0490, -0.0525,  0.0869],\n",
       "                       [ 0.0798, -0.0367, -0.0009,  ...,  0.0596, -0.0253, -0.0437],\n",
       "                       [-0.0480, -0.0108,  0.0226,  ..., -0.0677, -0.0542, -0.0751],\n",
       "                       ...,\n",
       "                       [-0.0434,  0.0648, -0.0695,  ..., -0.0521,  0.0477, -0.0615],\n",
       "                       [ 0.0880,  0.0876,  0.0245,  ..., -0.0267, -0.0790, -0.0298],\n",
       "                       [-0.0422,  0.0456,  0.0185,  ...,  0.0303,  0.0421, -0.0746]])),\n",
       "              ('layer3.bias',\n",
       "               tensor([ 0.0032,  0.0624, -0.0221,  0.0855,  0.0016, -0.0430,  0.0768,  0.0350,\n",
       "                        0.0275,  0.0847]))]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' 실험4 '''\n",
    "model.state_dict()[\"layer1.weight\"][0], model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e071185-db94-490b-b44f-be41e08fd9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time, os\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "from lib.model_testing2 import worker\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "def model(x, unpacked_params):\n",
    "    l1, b1, l2, b2, l3, b3 = unpacked_params\n",
    "    y = torch.nn.functional.linear(x, l1, b1) # torch.nn.functional.linear()에는 입력과 가중치 텐서, 편향 텐서가 인자로 전달된다\n",
    "    y = torch.relu(y)\n",
    "    y = torch.nn.functional.linear(y, l2, b2)\n",
    "    y = torch.relu(y)\n",
    "    y = torch.nn.functional.linear(y, l3, b3)\n",
    "    y = torch.log_softmax(y, dim=0)\n",
    "\n",
    "    return y\n",
    "\n",
    "def unpack_params(params, layers=[(25, 4), (10, 25), (2, 10)]):\n",
    "    # 만약 어떤 은닉층이 노드가 10개이고 크기가 4인 1차원 텐서가 입력이라면\n",
    "    # 이 은닉층의 가중치 텐서는 10 X 4 형태의 텐서가 된다\n",
    "    # params는 모델을 이루는 모든 계층들의 학습 가능한 매개변수들을 1차원 텐서 형태로 만들어 놓은 것이다(flatten)\n",
    "    unpacked_params = []\n",
    "    e = 0\n",
    "    for i, l in enumerate(layers):\n",
    "        s, e = e, e + np.prod(l) # np.prod()는 주어진 축(axis) 상의 배열 원소들에 대한 곱을 수행한다\n",
    "        weights = params[s:e].view(l) # 첫 번째 은닉층부터 시작하여 각 계층의 가중치 텐서를 params로부터 추출한다\n",
    "        s, e = e, e+l[0]\n",
    "        bias = params[s:e] # 첫 번째 은닉층부터 시작하여 각 계층의 편향 텐서를 params로부터 추출한다\n",
    "        unpacked_params.extend([weights, bias])\n",
    "\n",
    "    return unpacked_params\n",
    "\n",
    "def spawn_population(N=50, size=407):\n",
    "    pop = [] # 개체군\n",
    "    for i in range(N):\n",
    "        vec = torch.randn(size) / 2.0 # 모델의 모든 학습 가능한 매개변수에 해당하는 무작위한 값들로 채워진 1차원 텐서를 생성한다\n",
    "        fit = 0 # 각 개체의 적합도\n",
    "        p = {\"params\":vec, \"fitness\":fit} # 개체 생성\n",
    "        pop.append(p)\n",
    "\n",
    "    return pop\n",
    "\n",
    "def recombine(x1, x2):\n",
    "    x1 = x1[\"params\"] # 모델의 flatten된 매개변수 텐서를 불러온다\n",
    "    x2 = x2[\"params\"]\n",
    "    l = x1.shape[0]\n",
    "    split_pt = np.random.randint(l)\n",
    "    child1 = torch.zeros(l)\n",
    "    child2 = torch.zeros(l)\n",
    "    # 첫 번째 자손 개체 생성\n",
    "    child1[0:split_pt] = x1[0:split_pt]\n",
    "    child1[split_pt:] = x2[split_pt:]\n",
    "    # 두 번째 자손 개체 생성\n",
    "    child2[0:split_pt] = x2[:split_pt]\n",
    "    child2[split_pt:] = x1[split_pt:]\n",
    "    # 최종 자손 개체\n",
    "    c1 = {\"params\":child1, \"fitness\":0.0}\n",
    "    c2 = {\"params\":child2, \"fitness\":0.0}\n",
    "\n",
    "    return c1, c2\n",
    "\n",
    "def mutate(x, rate=0.01):\n",
    "    x_ = x[\"params\"]\n",
    "    num_to_change = int(rate*x_.shape[0]) # 자손 개체의 매개변수들 중 변이시킬 매개변수 비율을 결정한다\n",
    "    idx = np.random.randint(low=0, high=x_.shape[0], size=(num_to_change,)) # 결정된 비율만큼의 매개변수 인덱스를 반환한다\n",
    "    x_[idx] = torch.randn(num_to_change) / 10.0 # 선택된 매개변수들을 모두 무작위 실수 값으로 변경한다\n",
    "                                                # 10.0으로 굳이 나누어 준 것은 모든 무작위 실수 값들이 0.xxx의 형태로 표현되도록 만들어 주기 위함이다\n",
    "    x[\"params\"] = x_\n",
    "\n",
    "    return x\n",
    "\n",
    "def test_model(agent):\n",
    "    done = False\n",
    "    s = env.reset()[0]\n",
    "    state = torch.from_numpy(s).float()\n",
    "    score = 0\n",
    "    while not done: # done = True이면 반복문이 종료된다\n",
    "        params = unpack_params(agent[\"params\"])\n",
    "        probs = model(state, params)\n",
    "        action = torch.distributions.categorical.Categorical(probs=probs).sample() # logit을 바탕으로 카테고리컬 분포(즉, 확률분포)를 구성한 후, 그에 따라 행동 1개를 선택한다\n",
    "        state_, reward, done, _, info = env.step(action.item())\n",
    "        state = torch.from_numpy(state_).float()\n",
    "        score += 1 # 에피소드의 길이를 각 개체에 대한 적합도 점수로 간주한다\n",
    "\n",
    "    return score\n",
    "\n",
    "def evaluate_population(pop):\n",
    "    tot_fit = 0\n",
    "    lp = len(pop) # lp = length population\n",
    "    for agent in pop:\n",
    "        score = test_model(agent)\n",
    "        agent[\"fitness\"] = score\n",
    "        tot_fit += score\n",
    "    avg_fit = tot_fit / lp # 개체군 내 모든 개체들의 적합도에 대한 평균을 계산한다\n",
    "\n",
    "    return pop, avg_fit\n",
    "\n",
    "def next_generation(pop, mut_rate=0.001, tournament_size=0.2):\n",
    "    new_pop = []\n",
    "    lp = len(pop) # lp = length population\n",
    "    while len(new_pop) < len(pop):\n",
    "        rids = np.random.randint(low=0, high=lp, size=(int(tournament_size*lp))) # [0, lp) 구간에서 (tournament_size*lp) 만큼의 무작위 정수들을 추출한다\n",
    "                                                                                 # 즉, 전체 개체군에서 부모 개체를 선택하기 위한 부분 집합을 선발한다\n",
    "        batch = np.array([[i, x[\"fitness\"]] for (i, x) in enumerate(pop) if i in rids])\n",
    "        scores = batch[batch[:, 1].argsort()] # np.argsort()는 주어진 축(axis)에 따라 배열을 (내림차순으로)정렬한 후, 그 형태를 유지한 채로 각 원소들이 정렬되기 전 원래 가졌었던 인덱스를 반환한다\n",
    "                                              # scores는 적합도를 기준으로 내림차순으로 정렬된 개체 정보 ndarray이다\n",
    "        i0, i1 = int(scores[-1][0]), int(scores[-2][0]) # scores가 내림차순으로 정렬되어 있으므로 적합도가 가장 높은 개체는 맨 마지막에서 첫 번째와 두 번째 개체가 된다\n",
    "                                                       # 적합도가 가장 큰 두 개체의 개체군 내 인덱스를 반환한다\n",
    "        parent0, parent1 = pop[i0], pop[i1] # 부모 개체\n",
    "        offspring_ = recombine(parent0, parent1)\n",
    "        child1 = mutate(offspring_[0], rate=mut_rate)\n",
    "        child2 = mutate(offspring_[1], rate=mut_rate)\n",
    "        offspring = [child1, child2] # 최종 자손 개체\n",
    "        new_pop.extend(offspring)\n",
    "\n",
    "    return new_pop\n",
    "\n",
    "def max_gene(pop):\n",
    "    pop, _ = evaluate_population(pop)\n",
    "    max_fitness = 0\n",
    "    for x in pop:\n",
    "        if x[\"fitness\"] > max_fitness: max_fitness = x[\"fitness\"]\n",
    "\n",
    "    return max_fitness\n",
    "\n",
    "def running_mean(x, n=5): # 개체군 마다의 적합도 평균 모음을 입력으로 받는다\n",
    "    conv = np.ones(n) # 데이터를 n개 단위로 행렬곱을 통해 합산하기 위한 것이다\n",
    "    y = np.zeros(x.shape[0] - n + 1) # 전체 데이터를 T라고 했을 때 n개의 데이터를 한 개의 집합으로 간주하면, 총 T - n + 1개의 집합이 도출된다\n",
    "    for i in range(x.shape[0] - n + 1):\n",
    "        y[i] = (conv @ x[i:i+n]) / n # 데이터를 n개 단위로 평균을 계산한다\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c57df04-6ada-4fd7-a44e-a03576a3ee63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen 1\n",
      "Gen 2\n",
      "Gen 3\n",
      "Gen 4\n",
      "Gen 5\n",
      "Gen 6\n",
      "Gen 7\n",
      "Gen 8\n",
      "Gen 9\n",
      "Gen 10\n",
      "Gen 11\n",
      "Gen 12\n",
      "Gen 13\n",
      "Gen 14\n",
      "Gen 15\n",
      "Gen 16\n",
      "Gen 17\n",
      "Gen 18\n",
      "Gen 19\n",
      "Gen 20\n",
      "running time : 103.2442 min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fa5747b9e0>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_generations = 20\n",
    "population_size = 500\n",
    "mutation_rate = 0.01 # 1%\n",
    "pop_fit = []\n",
    "pop = spawn_population(N=population_size, size=407)\n",
    "\n",
    "start = time.time()\n",
    "for i in range(num_generations):\n",
    "    print(f\"Gen {i+1}\")\n",
    "    pop, avg_fit = evaluate_population(pop)\n",
    "    pop_fit.append(avg_fit)\n",
    "    pop = next_generation(pop, mut_rate=mutation_rate, tournament_size=0.2)\n",
    "print(f\"running time : {(time.time() - start) / 60:.4f} min\")\n",
    "# print(pop_fit, running_mean(np.array(pop_fit), 3))\n",
    "print(f\"max fitness of gene of final population : {max_gene(pop)}\")\n",
    "\n",
    "''' 개체군 저장 '''\n",
    "torch.save(pop, os.path.join(os.getcwd(), \"parameters\", \"population1.pt\"))\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.xlabel(\"Generations\", fontsize=22)\n",
    "plt.ylabel(\"Score\", fontsize=22)\n",
    "plt.plot(running_mean(np.array(pop_fit), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a715781d-dc43-447c-adca-751e7ddc5358",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 최종 개체군 중 최고의 적합도를 가진 개체에 대한 카트폴 실험 '''\n",
    "\n",
    "''' 프로세스 생성 및 실행 '''\n",
    "p = mp.Process(target=worker, args=(pop,))\n",
    "p.start()\n",
    "\n",
    "''' 프로세스 종료 및 자원 회수 '''\n",
    "p.join()\n",
    "p.terminate()\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9d0b143-e184-4e2e-b682-1a2eba10d9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 책에서 소개하는 코드의 최적화 버전 '''\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time, os\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "from lib.model_testing2 import worker\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "def model(x, unpacked_params):\n",
    "    l1, b1, l2, b2, l3, b3 = unpacked_params\n",
    "    y = torch.nn.functional.linear(x, l1, b1) # torch.nn.functional.linear()에는 입력과 가중치 텐서, 편향 텐서가 인자로 전달된다\n",
    "    y = torch.relu(y)\n",
    "    y = torch.nn.functional.linear(y, l2, b2)\n",
    "    y = torch.relu(y)\n",
    "    y = torch.nn.functional.linear(y, l3, b3)\n",
    "    y = torch.log_softmax(y, dim=0)\n",
    "\n",
    "    return y\n",
    "\n",
    "def unpack_params(params, layers=[(25, 4), (10, 25), (2, 10)]):\n",
    "    # 만약 어떤 은닉층이 노드가 10개이고 크기가 4인 1차원 텐서가 입력이라면\n",
    "    # 이 은닉층의 가중치 텐서는 10 X 4 형태의 텐서가 된다\n",
    "    # params는 모델을 이루는 모든 계층들의 학습 가능한 매개변수들을 1차원 텐서 형태로 만들어 놓은 것이다(flatten)\n",
    "    unpacked_params = []\n",
    "    e = 0\n",
    "    for i, l in enumerate(layers):\n",
    "        s, e = e, e + np.prod(l) # np.prod()는 주어진 축(axis) 상의 배열 원소들에 대한 곱을 수행한다\n",
    "        weights = params[s:e].view(l) # 첫 번째 은닉층부터 시작하여 각 계층의 가중치 텐서를 params로부터 추출한다\n",
    "        s, e = e, e+l[0]\n",
    "        bias = params[s:e] # 첫 번째 은닉층부터 시작하여 각 계층의 편향 텐서를 params로부터 추출한다\n",
    "        unpacked_params.extend([weights, bias])\n",
    "\n",
    "    return unpacked_params\n",
    "\n",
    "def spawn_population(N=50, size=407):\n",
    "    # 개체군\n",
    "    pop = [{\"params\":(torch.randn(size) / 2.0), \"fitness\":0.0} for i in range(N)] # 모델의 모든 학습 가능한 매개변수에 해당하는 무작위한 값들로 채워진 1차원 텐서를 생성한다(개체 생성)\n",
    "\n",
    "    return pop\n",
    "\n",
    "def recombine(x1, x2):\n",
    "    x1 = x1[\"params\"] # 모델의 flatten된 매개변수 텐서를 불러온다\n",
    "    x2 = x2[\"params\"]\n",
    "    split_pt = np.random.randint(x1.shape[0]) # pt = point\n",
    "    # 최종 자손 개체\n",
    "    child1 = {\"params\":torch.cat((x1[0:split_pt], x2[split_pt:]), dim=0), \"fitness\":0.0} # 첫 번째 자손 개체 생성\n",
    "    child2 = {\"params\":torch.cat((x2[0:split_pt], x1[split_pt:]), dim=0), \"fitness\":0.0} # 두 번째 자손 개체 생성\n",
    "\n",
    "    return child1, child2\n",
    "\n",
    "def recombine2(x1, x2):\n",
    "    x1 = x1[\"params\"] # 모델의 flatten된 매개변수 텐서를 불러온다\n",
    "    x2 = x2[\"params\"]\n",
    "    l = x1.shape[0]\n",
    "    split_pt = np.random.randint(l)\n",
    "    child1 = torch.zeros(l)\n",
    "    child2 = torch.zeros(l)\n",
    "    # 첫 번째 자손 개체 생성\n",
    "    child1[0:split_pt] = x1[0:split_pt]\n",
    "    child1[split_pt:] = x2[split_pt:]\n",
    "    # 두 번째 자손 개체 생성\n",
    "    child2[0:split_pt] = x2[:split_pt]\n",
    "    child2[split_pt:] = x1[split_pt:]\n",
    "    # 최종 자손 개체\n",
    "    c1 = {\"params\":child1, \"fitness\":0.0}\n",
    "    c2 = {\"params\":child2, \"fitness\":0.0}\n",
    "\n",
    "    return c1, c2\n",
    "\n",
    "def mutate(x, rate=0.01):\n",
    "    x_params = x[\"params\"]\n",
    "    num_to_change = int(rate*x_params.shape[0]) # 자손 개체의 매개변수들 중 변이시킬 매개변수 비율을 결정한다\n",
    "    idx = np.random.randint(low=0, high=x_params.shape[0], size=(num_to_change,)) # 결정된 비율만큼의 매개변수 인덱스를 반환한다\n",
    "    x_params[idx] = torch.randn(num_to_change) / 10.0 # 선택된 매개변수들을 모두 무작위 실수 값으로 변경한다\n",
    "                                                      # 10.0으로 굳이 나누어 준 것은 모든 무작위 실수 값들이 0.xxx의 형태로 표현되도록 만들어 주기 위함이다\n",
    "    x[\"params\"] = x_params\n",
    "\n",
    "    return x\n",
    "\n",
    "def test_model(agent):\n",
    "    done = False\n",
    "    cur_state = torch.from_numpy(env.reset()[0]).float()\n",
    "    score = 0\n",
    "    agent_params = unpack_params(agent[\"params\"]) # 개체의 매개변수 벡터를 모델의 각 계층에 넣어줄 수 있는 형식으로 변환한다\n",
    "    while not done: # done = True이면 반복문이 종료된다\n",
    "        probs = model(cur_state, agent_params)\n",
    "        action = torch.distributions.categorical.Categorical(probs=probs).sample() # logit을 바탕으로 카테고리컬 분포(즉, 확률분포)를 구성한 후, 그에 따라 행동 1개를 선택한다\n",
    "        next_state, _, done, _, _ = env.step(action.item())\n",
    "        cur_state = torch.from_numpy(next_state).float()\n",
    "        score += 1 # 에피소드의 길이를 각 개체에 대한 적합도 점수로 간주한다\n",
    "\n",
    "    return score\n",
    "\n",
    "def evaluate_population(pop):\n",
    "    tot_fit = 0\n",
    "    lp = len(pop) # lp = length population\n",
    "    for agent in pop:\n",
    "        score = test_model(agent) # 개체가 카트폴 환경에 얼마나 적합한지 평가한다\n",
    "        agent[\"fitness\"] = score\n",
    "        tot_fit += score\n",
    "    avg_fit = tot_fit / lp # 개체군 내 모든 개체들의 적합도에 대한 평균을 계산한다\n",
    "\n",
    "    return pop, avg_fit\n",
    "\n",
    "def next_generation(pop, mut_rate=0.001, tournament_size=0.2):\n",
    "    new_pop = []\n",
    "    lp = len(pop) # lp = length population\n",
    "    while len(new_pop) < len(pop):\n",
    "        selection = np.random.randint(low=0, high=lp, size=(int(tournament_size*lp))) # [0, lp) 구간에서 (tournament_size*lp) 만큼의 무작위 정수들을 추출한다\n",
    "                                                                                      # 즉, 전체 개체군에서 부모 개체를 선택하기 위한 부분 집합을 선발한다\n",
    "        sg = np.array([[i, x[\"fitness\"]] for (i, x) in enumerate(pop) if i in selection]) # sg = selection group\n",
    "        scores = sg[sg[:, 1].argsort()] # np.argsort()는 주어진 축(axis)에 따라 배열을 (내림차순으로)정렬한 후, 그 형태를 유지한 채로 각 원소들이 정렬되기 전 원래 가졌었던 인덱스를 반환한다\n",
    "                                        # scores는 적합도를 기준으로 내림차순으로 정렬된 개체 정보 ndarray이다\n",
    "        p0, p1 = pop[scores[-1][0]], pop[scores[-2][0]] # scores는 sg 내의 개체들을 내림차순으로 정렬한 것이므로 적합도가 가장 큰 개체는 맨 마지막에서 첫 번째와 두 번째 개체가 된다\n",
    "                                                                  # 적합도가 가장 큰 두 개체의 개체군 내 인덱스를 반환한다\n",
    "        offspring = recombine(p0, p1)\n",
    "        # offspring = recombine2(p0, p1)\n",
    "        child1 = mutate(offspring[0], rate=mut_rate)\n",
    "        child2 = mutate(offspring[1], rate=mut_rate)\n",
    "        new_pop.extend([child1, child2])\n",
    "        # new_pop.extend([mutate(offspring[0], rate=mut_rate), mutate(offspring[1], rate=mut_rate)]) # 최종 자손 개체\n",
    "\n",
    "    return new_pop\n",
    "\n",
    "def max_gene(pop):\n",
    "    pop, _ = evaluate_population(pop)\n",
    "    max_fitness = 0\n",
    "    for x in pop:\n",
    "        if x[\"fitness\"] > max_fitness: max_fitness = x[\"fitness\"]\n",
    "\n",
    "    return max_fitness\n",
    "\n",
    "def running_mean(x, n=5): # 개체군 마다의 적합도 평균 모음을 입력으로 받는다\n",
    "    conv = np.ones(n) # 데이터를 n개 단위로 행렬곱을 통해 합산하기 위한 커널(필터)이다\n",
    "    y = np.zeros(x.shape[0] - n + 1) # 전체 데이터를 T라고 했을 때 n개의 데이터를 한 개의 집합으로 간주하면, 총 T - n + 1개의 집합이 도출된다\n",
    "    for i in range(x.shape[0] - n + 1):\n",
    "        y[i] = (conv @ x[i:i+n]) / n # 데이터를 n개 단위로 평균을 계산한다\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b4b44bf-626d-431e-aafd-bae8702a7884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen 1\n",
      "500\n",
      "Gen 2\n",
      "500\n",
      "Gen 3\n",
      "500\n",
      "Gen 4\n",
      "500\n",
      "Gen 5\n",
      "500\n",
      "Gen 6\n",
      "500\n",
      "Gen 7\n",
      "500\n",
      "Gen 8\n",
      "500\n",
      "Gen 9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_generations):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGen \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     pop, avg_fit \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_population\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 개체군 내 개체들에 적합도 점수를 부여하고, 개체들의 적합도 점수 평균을 반환한다\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     pop_fit\u001b[38;5;241m.\u001b[39mappend(avg_fit)\n\u001b[0;32m     12\u001b[0m     pop \u001b[38;5;241m=\u001b[39m next_generation(pop, mut_rate\u001b[38;5;241m=\u001b[39mmutation_rate, tournament_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m)\n",
      "Cell \u001b[1;32mIn[24], line 101\u001b[0m, in \u001b[0;36mevaluate_population\u001b[1;34m(pop)\u001b[0m\n\u001b[0;32m     99\u001b[0m lp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(pop) \u001b[38;5;66;03m# lp = length population\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m pop:\n\u001b[1;32m--> 101\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 개체가 카트폴 환경에 얼마나 적합한지 평가한다\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     agent[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m score\n\u001b[0;32m    103\u001b[0m     tot_fit \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m score\n",
      "Cell \u001b[1;32mIn[24], line 90\u001b[0m, in \u001b[0;36mtest_model\u001b[1;34m(agent)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done: \u001b[38;5;66;03m# done = True이면 반복문이 종료된다\u001b[39;00m\n\u001b[0;32m     89\u001b[0m     probs \u001b[38;5;241m=\u001b[39m model(cur_state, agent_params)\n\u001b[1;32m---> 90\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprobs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# logit을 바탕으로 카테고리컬 분포(즉, 확률분포)를 구성한 후, 그에 따라 행동 1개를 선택한다\u001b[39;00m\n\u001b[0;32m     91\u001b[0m     next_state, _, done, _, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     92\u001b[0m     cur_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(next_state)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[1;32mD:\\Conda_envs\\reinfenv\\Lib\\site-packages\\torch\\distributions\\categorical.py:133\u001b[0m, in \u001b[0;36mCategorical.sample\u001b[1;34m(self, sample_shape)\u001b[0m\n\u001b[0;32m    131\u001b[0m     sample_shape \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize(sample_shape)\n\u001b[0;32m    132\u001b[0m probs_2d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobs\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_events)\n\u001b[1;32m--> 133\u001b[0m samples_2d \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs_2d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m samples_2d\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extended_shape(sample_shape))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_generations = 20\n",
    "population_size = 500\n",
    "mutation_rate = 0.01 # 0.1%\n",
    "pop_fit = []\n",
    "pop = spawn_population(N=population_size, size=407)\n",
    "\n",
    "start = time.time()\n",
    "for i in range(num_generations):\n",
    "    print(f\"Gen {i+1}\")\n",
    "    pop, avg_fit = evaluate_population(pop) # 개체군 내 개체들에 적합도 점수를 부여하고, 개체들의 적합도 점수 평균을 반환한다\n",
    "    pop_fit.append(avg_fit)\n",
    "    pop = next_generation(pop, mut_rate=mutation_rate, tournament_size=0.4)\n",
    "print(f\"running time : {(time.time() - start) / 60:.4f} min\")\n",
    "# print(pop_fit, running_mean(np.array(pop_fit), 3))\n",
    "print(f\"max fitness of gene of final population : {max_gene(pop)}\")\n",
    "\n",
    "''' 개체군 저장 '''\n",
    "torch.save(pop, os.path.join(os.getcwd(), \"parameters\", \"population2.pt\"))\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.xlabel(\"Generations\", fontsize=22)\n",
    "plt.ylabel(\"Score\", fontsize=22)\n",
    "plt.plot(running_mean(np.array(pop_fit), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64bc45bb-0895-401b-9771-7b9a1dfc04cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 481,   25],\n",
       "       [ 120,   34],\n",
       "       [  24,   35],\n",
       "       [ 315,   36],\n",
       "       [  13,   43],\n",
       "       [ 333,   67],\n",
       "       [ 298,   69],\n",
       "       [ 269,   89],\n",
       "       [ 145,  124],\n",
       "       [ 395,  139],\n",
       "       [ 254,  144],\n",
       "       [ 172,  163],\n",
       "       [ 187,  164],\n",
       "       [ 276,  164],\n",
       "       [ 490,  166],\n",
       "       [ 185,  184],\n",
       "       [ 474,  185],\n",
       "       [ 170,  192],\n",
       "       [ 232,  194],\n",
       "       [ 192,  201],\n",
       "       [ 204,  204],\n",
       "       [   3,  207],\n",
       "       [ 262,  207],\n",
       "       [ 141,  210],\n",
       "       [  45,  212],\n",
       "       [ 336,  213],\n",
       "       [ 497,  219],\n",
       "       [ 243,  228],\n",
       "       [ 180,  230],\n",
       "       [  78,  230],\n",
       "       [ 432,  239],\n",
       "       [ 247,  245],\n",
       "       [  96,  247],\n",
       "       [  49,  255],\n",
       "       [  71,  256],\n",
       "       [  17,  258],\n",
       "       [  63,  292],\n",
       "       [ 265,  295],\n",
       "       [  34,  300],\n",
       "       [ 118,  302],\n",
       "       [ 377,  307],\n",
       "       [ 291,  316],\n",
       "       [ 339,  316],\n",
       "       [ 188,  325],\n",
       "       [ 287,  332],\n",
       "       [ 381,  341],\n",
       "       [ 380,  352],\n",
       "       [ 167,  354],\n",
       "       [ 396,  361],\n",
       "       [  19,  371],\n",
       "       [ 493,  377],\n",
       "       [ 379,  378],\n",
       "       [ 375,  385],\n",
       "       [  16,  397],\n",
       "       [ 149,  430],\n",
       "       [ 302,  431],\n",
       "       [ 106,  433],\n",
       "       [ 397,  437],\n",
       "       [ 197,  440],\n",
       "       [ 177,  440],\n",
       "       [ 388,  453],\n",
       "       [ 263,  453],\n",
       "       [ 249,  461],\n",
       "       [ 163,  493],\n",
       "       [ 494,  507],\n",
       "       [ 305,  513],\n",
       "       [ 322,  519],\n",
       "       [ 318,  545],\n",
       "       [ 383,  562],\n",
       "       [ 105,  587],\n",
       "       [ 338,  606],\n",
       "       [ 358,  609],\n",
       "       [ 293,  641],\n",
       "       [ 271,  646],\n",
       "       [ 480,  660],\n",
       "       [  62,  670],\n",
       "       [ 434,  673],\n",
       "       [ 219,  680],\n",
       "       [ 110,  682],\n",
       "       [  75,  788],\n",
       "       [ 443,  811],\n",
       "       [ 386,  896],\n",
       "       [ 184, 1003],\n",
       "       [ 482, 1304],\n",
       "       [ 266, 1450],\n",
       "       [ 317, 1450]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp = len(pop)\n",
    "selection = np.random.randint(low=0, high=lp, size=(int(0.2*lp))) # [0, lp) 구간에서 (tournament_size*lp) 만큼의 무작위 정수들을 추출한다\n",
    "                                                                                      # 즉, 전체 개체군에서 부모 개체를 선택하기 위한 부분 집합을 선발한다\n",
    "sg = np.array([[i, x[\"fitness\"]] for (i, x) in enumerate(pop) if i in selection]) # sg = selection group\n",
    "scores = sg[sg[:, 1].argsort()] # np.argsort()는 주어진 축(axis)에 따라 배열을 (내림차순으로)정렬한 후, 그 형태를 유지한 채로 각 원소들이 정렬되기 전 원래 가졌었던 인덱스를 반환한다\n",
    "                                # scores는 적합도를 기준으로 내림차순으로 정렬된 개체 정보 ndarray이다\n",
    "scores\n",
    "# p0, p1 = pop[scores[-1][0]], pop[scores[-2][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d5c220c-817a-4504-9e83-19069695baba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n",
      "184\n",
      "218\n",
      "207\n",
      "742\n",
      "289\n",
      "328\n",
      "676\n",
      "254\n",
      "195\n",
      "1021\n",
      "384\n",
      "174\n",
      "43\n",
      "373\n",
      "193\n",
      "397\n",
      "258\n",
      "898\n",
      "371\n",
      "139\n",
      "80\n",
      "29\n",
      "204\n",
      "35\n",
      "1397\n",
      "857\n",
      "94\n",
      "259\n",
      "1263\n",
      "693\n",
      "727\n",
      "194\n",
      "322\n",
      "300\n",
      "317\n",
      "191\n",
      "123\n",
      "287\n",
      "293\n",
      "555\n",
      "165\n",
      "304\n",
      "540\n",
      "2583\n",
      "212\n",
      "310\n",
      "200\n",
      "215\n",
      "255\n",
      "415\n",
      "720\n",
      "139\n",
      "298\n",
      "475\n",
      "821\n",
      "616\n",
      "1389\n",
      "246\n",
      "514\n",
      "144\n",
      "914\n",
      "670\n",
      "292\n",
      "310\n",
      "79\n",
      "662\n",
      "552\n",
      "101\n",
      "441\n",
      "553\n",
      "256\n",
      "1075\n",
      "1410\n",
      "370\n",
      "788\n",
      "24\n",
      "883\n",
      "230\n",
      "205\n",
      "172\n",
      "274\n",
      "893\n",
      "244\n",
      "498\n",
      "177\n",
      "137\n",
      "670\n",
      "340\n",
      "174\n",
      "592\n",
      "273\n",
      "1233\n",
      "386\n",
      "259\n",
      "186\n",
      "247\n",
      "490\n",
      "851\n",
      "197\n",
      "378\n",
      "132\n",
      "638\n",
      "327\n",
      "238\n",
      "587\n",
      "433\n",
      "684\n",
      "417\n",
      "876\n",
      "682\n",
      "548\n",
      "722\n",
      "648\n",
      "378\n",
      "375\n",
      "318\n",
      "340\n",
      "302\n",
      "175\n",
      "34\n",
      "948\n",
      "299\n",
      "481\n",
      "390\n",
      "449\n",
      "281\n",
      "212\n",
      "261\n",
      "930\n",
      "363\n",
      "310\n",
      "476\n",
      "390\n",
      "286\n",
      "294\n",
      "249\n",
      "200\n",
      "751\n",
      "22\n",
      "197\n",
      "210\n",
      "333\n",
      "436\n",
      "1027\n",
      "124\n",
      "637\n",
      "533\n",
      "1541\n",
      "430\n",
      "394\n",
      "27\n",
      "1495\n",
      "321\n",
      "81\n",
      "890\n",
      "350\n",
      "314\n",
      "394\n",
      "142\n",
      "1506\n",
      "162\n",
      "213\n",
      "493\n",
      "241\n",
      "305\n",
      "479\n",
      "354\n",
      "245\n",
      "338\n",
      "192\n",
      "288\n",
      "163\n",
      "559\n",
      "440\n",
      "450\n",
      "335\n",
      "440\n",
      "590\n",
      "108\n",
      "230\n",
      "1045\n",
      "425\n",
      "314\n",
      "1003\n",
      "184\n",
      "177\n",
      "164\n",
      "325\n",
      "60\n",
      "293\n",
      "1220\n",
      "201\n",
      "342\n",
      "533\n",
      "287\n",
      "332\n",
      "440\n",
      "365\n",
      "231\n",
      "282\n",
      "129\n",
      "159\n",
      "365\n",
      "204\n",
      "349\n",
      "293\n",
      "117\n",
      "256\n",
      "355\n",
      "259\n",
      "1257\n",
      "352\n",
      "272\n",
      "639\n",
      "1256\n",
      "1223\n",
      "132\n",
      "423\n",
      "680\n",
      "368\n",
      "1367\n",
      "156\n",
      "14\n",
      "203\n",
      "212\n",
      "188\n",
      "232\n",
      "667\n",
      "499\n",
      "264\n",
      "54\n",
      "194\n",
      "246\n",
      "194\n",
      "350\n",
      "406\n",
      "344\n",
      "14\n",
      "576\n",
      "64\n",
      "528\n",
      "1277\n",
      "228\n",
      "411\n",
      "566\n",
      "519\n",
      "245\n",
      "227\n",
      "461\n",
      "30\n",
      "356\n",
      "250\n",
      "378\n",
      "144\n",
      "622\n",
      "507\n",
      "1026\n",
      "408\n",
      "41\n",
      "195\n",
      "165\n",
      "207\n",
      "453\n",
      "252\n",
      "295\n",
      "1450\n",
      "1130\n",
      "516\n",
      "89\n",
      "276\n",
      "646\n",
      "103\n",
      "200\n",
      "116\n",
      "581\n",
      "164\n",
      "605\n",
      "314\n",
      "208\n",
      "367\n",
      "964\n",
      "332\n",
      "294\n",
      "908\n",
      "240\n",
      "283\n",
      "332\n",
      "374\n",
      "127\n",
      "179\n",
      "316\n",
      "644\n",
      "641\n",
      "689\n",
      "444\n",
      "765\n",
      "41\n",
      "69\n",
      "1440\n",
      "447\n",
      "708\n",
      "431\n",
      "190\n",
      "171\n",
      "513\n",
      "381\n",
      "122\n",
      "2953\n",
      "308\n",
      "482\n",
      "222\n",
      "204\n",
      "358\n",
      "516\n",
      "36\n",
      "624\n",
      "1450\n",
      "545\n",
      "579\n",
      "729\n",
      "442\n",
      "519\n",
      "484\n",
      "593\n",
      "231\n",
      "162\n",
      "681\n",
      "420\n",
      "213\n",
      "449\n",
      "244\n",
      "232\n",
      "67\n",
      "744\n",
      "1241\n",
      "213\n",
      "244\n",
      "606\n",
      "316\n",
      "140\n",
      "40\n",
      "183\n",
      "155\n",
      "349\n",
      "464\n",
      "447\n",
      "1847\n",
      "169\n",
      "247\n",
      "464\n",
      "348\n",
      "1067\n",
      "620\n",
      "468\n",
      "143\n",
      "108\n",
      "451\n",
      "609\n",
      "363\n",
      "121\n",
      "104\n",
      "451\n",
      "91\n",
      "56\n",
      "512\n",
      "252\n",
      "267\n",
      "37\n",
      "254\n",
      "182\n",
      "300\n",
      "332\n",
      "489\n",
      "294\n",
      "385\n",
      "97\n",
      "307\n",
      "212\n",
      "378\n",
      "352\n",
      "341\n",
      "296\n",
      "562\n",
      "262\n",
      "489\n",
      "896\n",
      "330\n",
      "453\n",
      "714\n",
      "410\n",
      "409\n",
      "377\n",
      "1265\n",
      "256\n",
      "139\n",
      "361\n",
      "437\n",
      "623\n",
      "294\n",
      "332\n",
      "296\n",
      "341\n",
      "205\n",
      "182\n",
      "309\n",
      "418\n",
      "128\n",
      "155\n",
      "434\n",
      "637\n",
      "589\n",
      "298\n",
      "576\n",
      "471\n",
      "115\n",
      "345\n",
      "288\n",
      "265\n",
      "329\n",
      "515\n",
      "198\n",
      "437\n",
      "237\n",
      "219\n",
      "289\n",
      "444\n",
      "555\n",
      "330\n",
      "1136\n",
      "255\n",
      "590\n",
      "239\n",
      "311\n",
      "673\n",
      "198\n",
      "491\n",
      "188\n",
      "243\n",
      "96\n",
      "206\n",
      "460\n",
      "353\n",
      "811\n",
      "283\n",
      "612\n",
      "298\n",
      "336\n",
      "152\n",
      "306\n",
      "363\n",
      "215\n",
      "400\n",
      "330\n",
      "331\n",
      "263\n",
      "238\n",
      "237\n",
      "169\n",
      "289\n",
      "296\n",
      "347\n",
      "398\n",
      "454\n",
      "672\n",
      "344\n",
      "243\n",
      "296\n",
      "501\n",
      "486\n",
      "515\n",
      "477\n",
      "562\n",
      "185\n",
      "185\n",
      "134\n",
      "216\n",
      "214\n",
      "430\n",
      "249\n",
      "660\n",
      "25\n",
      "1304\n",
      "360\n",
      "162\n",
      "128\n",
      "262\n",
      "21\n",
      "332\n",
      "300\n",
      "166\n",
      "393\n",
      "267\n",
      "377\n",
      "507\n",
      "367\n",
      "377\n",
      "219\n",
      "360\n",
      "497\n"
     ]
    }
   ],
   "source": [
    "for x in pop:\n",
    "    print(x[\"fitness\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7267f1e1-216e-4fd0-b1b2-248504b8702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 최종 개체군 중 최고의 적합도를 가진 개체에 대한 카트폴 실험 '''\n",
    "\n",
    "''' 프로세스 생성 및 실행 '''\n",
    "p = mp.Process(target=worker, args=(pop,))\n",
    "p.start()\n",
    "\n",
    "''' 프로세스 종료 및 자원 회수 '''\n",
    "p.join()\n",
    "p.terminate()\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b15aac1-478f-4a6e-bc3c-6e96e2d08c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.6518,  1.2223, -0.1558, -1.3645,  1.1768, -0.9971,  0.3373,  0.2208,\n",
      "        -0.9163,  0.1216])\n",
      "a : tensor([50, 10, 87, 37, 26, 68, 38,  5, 87, 71, 89, 66, 20, 81, 43, 99, 32, 25,\n",
      "        95, 77])\n",
      "b : tensor([ 7, 13, 13,  2,  8, 11, 10,  8, 13, 13])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 5, 81, 81, 87, 87, 66, 89, 87, 81, 81]),\n",
       " tensor([ 1.1274, -1.8803, -0.1561, -1.4720,  1.6622]),\n",
       " tensor([ 0.1127, -0.1880, -0.0156, -0.1472,  0.1662]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((4,))\n",
    "y = torch.nn.functional.linear(x, torch.randn((10, 4)), torch.randn((10,)))\n",
    "print(y)\n",
    "\n",
    "a = torch.randint(low=0, high=100, size=(20,))\n",
    "b = torch.randint(low=0, high=20, size=(10,))\n",
    "print(\"a :\", a)\n",
    "print(\"b :\", b)\n",
    "c = torch.randn(5)\n",
    "a[b], c, c / 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e462c08d-ec30-4a32-8896-483d1c54e374",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 모델을 클래스로 구성한 버전 '''\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.multiprocessing as mp\n",
    "from lib.model_testing2 import worker\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "class LBRD_block(nn.Module):\n",
    "    def __init__(self, shape, out_layer=False dropout):\n",
    "        self.linear = nn.Linear(shape[1], shape[0])\n",
    "        self.batch_norm = nn.BatchNorm1d(shape[0])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.dropout(self.relu(self.batch_nomr(self.linear(x))))\n",
    "\n",
    "        return output\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, layers=[(25, 4), (10, 25), (2, 10)], dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(*[LBRD_block(shape, dropout) for shape in layers[:2]])\n",
    "        self.tail_top = nn.Linear(layers[-1][1], layers[-1][0])\n",
    "        sefl.tail_bottom = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.body(x)\n",
    "        output = self.tail_bottom(self.tail_top(output))\n",
    "\n",
    "        return output\n",
    "        \n",
    "\n",
    "def model(x, unpacked_params):\n",
    "    l1, b1, l2, b2, l3, b3 = unpacked_params\n",
    "    y = torch.nn.functional.linear(x, l1, b1) # torch.nn.functional.linear()에는 입력과 가중치 텐서, 편향 텐서가 인자로 전달된다\n",
    "    y = torch.relu(y)\n",
    "    y = torch.nn.functional.linear(y, l2, b2)\n",
    "    y = torch.relu(y)\n",
    "    y = torch.nn.functional.linear(y, l3, b3)\n",
    "    y = torch.log_softmax(y, dim=0)\n",
    "\n",
    "    return y\n",
    "\n",
    "def unpack_params(params, layers=[(25, 4), (10, 25), (2, 10)]):\n",
    "    # 만약 어떤 은닉층이 노드가 10개이고 크기가 4인 1차원 텐서가 입력이라면\n",
    "    # 이 은닉층의 가중치 텐서는 10 X 4 형태의 텐서가 된다\n",
    "    # params는 모델을 이루는 모든 계층들의 학습 가능한 매개변수들을 1차원 텐서 형태로 만들어 놓은 것이다(flatten)\n",
    "    unpacked_params = []\n",
    "    e = 0\n",
    "    for i, l in enumerate(layers):\n",
    "        s, e = e, e + np.prod(l) # np.prod()는 주어진 축(axis) 상의 배열 원소들에 대한 곱을 수행한다\n",
    "        weights = params[s:e].view(l) # 첫 번째 은닉층부터 시작하여 각 계층의 가중치 텐서를 params로부터 추출한다\n",
    "        s, e = e, e+l[0]\n",
    "        bias = params[s:e] # 첫 번째 은닉층부터 시작하여 각 계층의 편향 텐서를 params로부터 추출한다\n",
    "        unpacked_params.extend([weights, bias])\n",
    "\n",
    "    return unpacked_params\n",
    "\n",
    "def spawn_population(N=50, size=407):\n",
    "    pop = [] # 개체군\n",
    "    pop.extend([{\"params\":(torch.randn(size) / 2.0), \"fitness\":0} for i in range(N)]) # 모델의 모든 학습 가능한 매개변수에 해당하는 무작위한 값들로 채워진 1차원 텐서를 생성한다(개체 생성)\n",
    "\n",
    "    return pop\n",
    "\n",
    "def unpack_pop_for_layer(pop, layers=[(25, 4), (10, 25), (2, 10)]):\n",
    "    pop_for_layer1 = []\n",
    "    pop_for_layer2 = []\n",
    "    pop_for_layer3 = []\n",
    "    \n",
    "    for x in pop:\n",
    "        x[\"params\"]\n",
    "\n",
    "def recombine(x1, x2):\n",
    "    x1 = x1[\"params\"] # 모델의 flatten된 매개변수 텐서를 불러온다\n",
    "    x2 = x2[\"params\"]\n",
    "    split_pt = np.random.randint(x1.shape[0]) # pt = point\n",
    "    # 최종 자손 개체\n",
    "    child1 = {\"params\":torch.cat((x1[0:split_pt], x2[split_pt:]), dim=0), \"fitness\":0.0} # 첫 번째 자손 개체 생성\n",
    "    child2 = {\"params\":torch.cat((x2[0:split_pt], x1[split_pt:]), dim=0), \"fitness\":0.0} # 두 번째 자손 개체 생성\n",
    "\n",
    "    return child1, child2\n",
    "\n",
    "def mutate(x, rate=0.01):\n",
    "    x_params = x[\"params\"]\n",
    "    num_to_change = int(rate*x_params.shape[0]) # 자손 개체의 매개변수들 중 변이시킬 매개변수 비율을 결정한다\n",
    "    idx = np.random.randint(low=0, high=x_params.shape[0], size=(num_to_change,)) # 결정된 비율만큼의 매개변수 인덱스를 반환한다\n",
    "    x_params[idx] = torch.randn(num_to_change) / 10.0 # 선택된 매개변수들을 모두 무작위 실수 값으로 변경한다\n",
    "                                                      # 10.0으로 굳이 나누어 준 것은 모든 무작위 실수 값들이 0.xxx의 형태로 표현되도록 만들어 주기 위함이다\n",
    "    x[\"params\"] = x_params\n",
    "\n",
    "    return x\n",
    "\n",
    "def test_model(agent):\n",
    "    done = False\n",
    "    cur_state = torch.from_numpy(env.reset()[0]).float()\n",
    "    score = 0\n",
    "    agent_params = unpack_params(agent[\"params\"]) # 개체의 매개변수 벡터를 모델의 각 계층에 넣어줄 수 있는 형식으로 변환한다\n",
    "    while not done: # done = True이면 반복문이 종료된다\n",
    "        probs = model(cur_state, agent_params)\n",
    "        action = torch.distributions.categorical.Categorical(probs=probs).sample() # logit을 바탕으로 카테고리컬 분포(즉, 확률분포)를 구성한 후, 그에 따라 행동 1개를 선택한다\n",
    "        next_state_, _, done, _, _ = env.step(action.item())\n",
    "        cur_state = torch.from_numpy(next_state).float()\n",
    "        score += 1 # 에피소드의 길이를 각 개체에 대한 적합도 점수로 간주한다\n",
    "\n",
    "    return score\n",
    "\n",
    "def evaluate_population(pop):\n",
    "    tot_fit = 0\n",
    "    lp = len(pop) # lp = length population\n",
    "    for agent in pop:\n",
    "        score = test_model(agent) # 개체가 카트폴 환경에 얼마나 적합한지 평가한다\n",
    "        agent[\"fitness\"] = score\n",
    "        tot_fit += score\n",
    "    avg_fit = tot_fit / lp # 개체군 내 모든 개체들의 적합도에 대한 평균을 계산한다\n",
    "\n",
    "    return pop, avg_fit\n",
    "\n",
    "def next_generation(pop, mut_rate=0.001, tournament_size=0.2):\n",
    "    new_pop = []\n",
    "    lp = len(pop) # lp = length population\n",
    "    while len(new_pop) < len(pop):\n",
    "        selection = np.random.randint(low=0, high=lp, size=(int(tournament_size*lp))) # [0, lp) 구간에서 (tournament_size*lp) 만큼의 무작위 정수들을 추출한다\n",
    "                                                                                      # 즉, 전체 개체군에서 부모 개체를 선택하기 위한 부분 집합을 선발한다\n",
    "        sg = np.array([[i, x[\"fitness\"]] for (i, x) in enumerate(pop) if i in selection]) # sg = selection group\n",
    "        scores = sg[sg[:, 1].argsort()] # np.argsort()는 주어진 축(axis)에 따라 배열을 (내림차순으로)정렬한 후, 그 형태를 유지한 채로 각 원소들이 정렬되기 전 원래 가졌었던 인덱스를 반환한다\n",
    "                                        # scores는 적합도를 기준으로 내림차순으로 정렬된 개체 정보 ndarray이다\n",
    "        p0, p1 = pop[int(scores[-1][0])], pop[int(scores[-2][0])] # scores는 sg 내의 개체들을 내림차순으로 정렬한 것이므로 적합도가 가장 큰 개체는 맨 마지막에서 첫 번째와 두 번째 개체가 된다\n",
    "                                                                  # 적합도가 가장 큰 두 개체의 개체군 내 인덱스를 반환한다\n",
    "        offspring = recombine(p0, p1)\n",
    "        new_pop.extend([mutate(offspring[0], rate=mut_rate), mutate(offspring[1], rate=mut_rate)]) # 최종 자손 개체\n",
    "\n",
    "    print(len(pop), len(new_pop))\n",
    "    return new_pop\n",
    "\n",
    "def running_mean(x, n=5): # 개체군 마다의 적합도 평균 모음을 입력으로 받는다\n",
    "    conv = np.ones(n) # 데이터를 n개 단위로 행렬곱을 통해 합산하기 위한 커널(필터)이다\n",
    "    y = np.zeros(x.shape[0] - n + 1) # 전체 데이터를 T라고 했을 때 n개의 데이터를 한 개의 집합으로 간주하면, 총 T - n + 1개의 집합이 도출된다\n",
    "    for i in range(x.shape[0] - n + 1):\n",
    "        y[i] = (conv @ x[i:i+n]) / n # 데이터를 n개 단위로 평균을 계산한다\n",
    "\n",
    "    return y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
