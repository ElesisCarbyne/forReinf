{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "611de677-7bcf-486a-a866-e7a2b9580f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting dill>=0.3.8 (from multiprocess)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Installing collected packages: dill, multiprocess\n",
      "Successfully installed dill-0.3.8 multiprocess-0.70.16\n"
     ]
    }
   ],
   "source": [
    "# !pip install multiprocess # 이거 절대로 쓰면 안된다\n",
    "                            # 써봤다가 노트북(쥬피터 노트북이 아니다) 나갈 뻔했다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa7eb67f-b99a-4e78-b369-2bbe9b7c14e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63] <class 'numpy.ndarray'> int32\n",
      "Current Host System cpu core number : 16\n",
      "[array([ 0,  1,  4,  9, 16, 25, 36, 49]), array([ 64,  81, 100, 121, 144, 169, 196, 225]), array([256, 289, 324, 361, 400, 441, 484, 529]), array([576, 625, 676, 729, 784, 841, 900, 961]), array([1024, 1089, 1156, 1225, 1296, 1369, 1444, 1521]), array([1600, 1681, 1764, 1849, 1936, 2025, 2116, 2209]), array([2304, 2401, 2500, 2601, 2704, 2809, 2916, 3025]), array([3136, 3249, 3364, 3481, 3600, 3721, 3844, 3969])]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import os\n",
    "from lib.testwork import square\n",
    "\n",
    "'''\n",
    "    multiprocessing 모듈은 윈도우와 유닉스/리눅스에서 다르게 작동한다\n",
    "    <윈도우>\n",
    "    윈도우의 경우 fork() system call이 없어 새로운 프로세스를 시작(start)할 경우, 새로운 파이썬 인터프리터를 시작함과 동시에 전체 프로그램을 처음부터 다시 실행한다\n",
    "    따라서 'if __name__ == \"__main__\":'을 명시하지 않으면 프로세스 생성문을 계속 실행되기 때문에 프로세스의 생성이 무한히 반복된다\n",
    "    처음 파이썬 프로그램을 시작하여 생성된 첫번째 프로세스는 __name__에 \"__main__\"이 들어있지만 두번째 프로세스부터는 \"__mp_main__\"이 들어있다\n",
    "    따라서 'if __name__ == \"__main__\":'을 명시하여 코드를 작성하면, 새로이 시작된 프로세스가 프로그램의 처음부터 다시 실행하더라도 if문 안쪽의 (여기서는)mp.Pool(8)을 실행하지 않아 프로세스가 무한히 생성되는 것을 막는다\n",
    "    \n",
    "    <유닉스/리눅스>\n",
    "    유닉스/리눅스의 경우 fork() system call이 존재하기 때문에 새로운 프로세스 생성 명령이 실행되면 현재 프로세스를 복사하여 새로운 프로세스를 생성하고, 이 때 원본이 되는 프로세스를 \"부모 프로세스\" 복사된 프로세스를 \"자식 프로세스\"라고 한다\n",
    "    생성된 자식 프로세스는 프로그램의 처음부터 다시 실행하는 것이 아닌 mp.Pool(8)와 같은 프로세스 생성 명령 바로 다음 명령부터 실행하기 때문에 프로세스가 무한정 생성되지 않는다\n",
    "    정확히는 프로세스 생성 명령 바로 다음 명령부터 실행하는 것이 아니라 부모 프로세스에서 import된 것들과 전역 변수를(그 외는 확실하지 않음) 상속받고 배정받은 작업을 수행한다\n",
    "\n",
    "    <쥬피터에서 멀티-프로세싱이 안되는 이유>\n",
    "    \"윈도우\"에서 파이썬 파일(.py)을 사용한 일반적인 멀티-프로세싱 실행 과정은 아래와 같다\n",
    "    1. 새로운 프로세스 생성 명령을 호출하면 파이썬은 해당 명령을 호출한 (실제로 그런 것은 아니지만 이하 '부모 프로세스'라고 칭함)main module(.py 파일 혹은 전체 파이썬 코드가 저장된 파일)과 배정된 작업을 처리하기 위한 (이하 '데이터'라고 칭함)인자(데이터)를 pickle(serialize, 직렬화)하여 새로운 프로세스로 보낸다\n",
    "    2. 새로운 프로세스(이하 '자식 프로세스'라 칭함)는 새로운 파이썬 인터프리터를 실행하고 넘겨받은 main module(.py 파일)을 다시 import 한다(즉, .py 파일에 적힌 코드를 처음부터 다시 실행한다는 것이다)\n",
    "    3. 이후, 자식 프로세스는 전달받은 데이터를 unpickle(deserialize, 비직렬화)하고, 이를 입력 데이터로 하여 배정된 작업 함수를 호출한다\n",
    "    4. 자식 프로세스가 main modeule(.py 파일)의 실행을 완료하면, 배정된 작업(mp_func())에 해당하는 함수의 반환된 결과를 pickle(serialize, 직렬화)하여 부모 프로세스에게 보낸다\n",
    "    5. 부모 프로세스는 전달 받은 결과물을 unpickle(deserialize, 비직렬화)하여 취합하고, 나머지 파이썬 코드를 계속 실행한다\n",
    "    \n",
    "    헌데 쥬피터 노트북은(랩도 마찬가지) 일반적인 파이썬 스크립트가 아닌, 백그라운드에서 상호작용 가능한 파이썬 커널을 실행하고 있는 웹 애플리케이션이다\n",
    "    이는 쥬피터 노트북에서의 main module(여기서는 .ipynb 파일)이 일반적인 파이썬 스크립트가 아니라 파이썬 객체임을 의미한다\n",
    "    이러한 파이썬 객체는 pickle(serialize, 직렬화)할 수 없고 따라서 이를 새로운 프로세스에 보내줄 수 없다\n",
    "    따라서 새로운 프로세스가 생성될 수 없으며, 이것이 쥬피터 상에서 (if문을 둘째치고서라도)멀티-프로세싱이 작동하지 않는 이유다\n",
    "\n",
    "    <해결방법(4가지가 있지만 그 중 가장 간편한 방법)>\n",
    "    멀티 프로세싱으로 처리할 작업에 해당하는 함수를 따로 파이썬 파일(.py)로 생성하고 그것을 불러온다\n",
    "    위 방법이 가능한 이유는 아래와 같다\n",
    "    1. 윈도우 상에서 새로운 프로세스를 생성할 때 main module을 넘겨준다는 했는데, 이는 새로운 프로세스에 배정한 작업 함수가 main module내에 작성되어있기 때문이다\n",
    "    ==> 이 때 main module은 작업 함수가 작성되어있는 곳이 된다\n",
    "    ==> 위의 사실에 따라 작업에 해당하는 함수를 .py 파일로 별도로 생성하게 되면 pickle이 가능해져 main module을 새로운 프로세스에 전달해 줄 수 있게 된다\n",
    "    2. 작업을 별도의 .py 파일로 생성할 때 \"작업에 해당하는 함수만\" 작성하였고 \"프로세스 생성문은 작성하지 않았기 때문에\" 무한 프로세스 생성 루프에 빠지지 않는다(빠질 수 없다)\n",
    "    \n",
    "    <참고>\n",
    "    https://bobswinkels.com/posts/multiprocessing-python-windows-jupyter/\n",
    "    how to use pool.map in jupyter notebook : 검색 문구\n",
    "'''\n",
    "'''\n",
    "    윈도우에서의 파이썬 멀티프로세싱 모듈의 작동 방식을 정리하면 아래와 같다\n",
    "    A. 쥬피터를 사용하지 않는 경우\n",
    "        1. 프로세스 생성문을 실행하면 작업 함수가 작성되어 있는 부모 프로세스의 메인 모듈(파이썬 파일)을 처리해야할 데이터와 함께 pickle하여 생성할 프로세스에게 전달한다\n",
    "        2. 윈도우에서는 fork 시스템 콜이 없어 프로세스 생성문은 새로운 프로세스(역할상으로만 자식 프로세스에 해당한다)를 생성한다\n",
    "        3. 새로이 생성된 프로세스는 전달 받은 (unpickle한)메인 모듈을 처음부터 끝까지 다시 실행하는데, 이 때 무한 프로세스 생성 현상을 방지하기 위해 메인 모듈에 \"if __name__ == \"__main__\"\"을 작성한다\n",
    "        4. 작업이 완료된 프로세스들은 결과물을 pickle하여 모체 프로세스에게 전달한다\n",
    "        5. 부모 프로세스는 그것을 다시 unpickle하여 나머지 작업을 수행한다\n",
    "    B. 쥬피터를 사용하는 경우\n",
    "        1. 쥬피터 파일은 파이썬 객체 취급임으로 여기에 작업 함수를 작성하게 되면 main module이 pickle되지 않아 생성되는 프로세스에게 전달해 줄 수 없다(즉, 프로세스가 생성되지 못한다)\n",
    "        2. 따라서 작업 함수를 별도의 파이썬 파일에 작성하여야 해당 파일이 main module이 되어 새로운 프로세스를 생성할 수 있게 된다\n",
    "        3. 모체 프로세스가 main module과 처리해야할 데이터를 pickle하여 생성되는 프로세스에 전달한다(프로세스가 생성된다)\n",
    "        4. 이 때, main module에는 작업 함수와 그에 필요한 것들만 작성되기 때문에 무한 프로세스 생성 현상은 애초에 발생할 수 없게 된다(따라서 \"if __name__ == \"__main__\"\"을 작성할 필요가 없다)\n",
    "        5. 작업이 완료된 프로세스들은 결과물을 pickle하여 모체 프로세스에게 전달한다\n",
    "        6. 부모 프로세스는 그것을 다시 unpickle하여 나머지 작업을 수행한다\n",
    "\n",
    "    -x- 파이썬에서의 프로세스는 자신만의 파이썬 인터프리터이를 갖으며, 단일 스레드 프로세스이다(따라서 GIL의 성능 저하 문제를 겪지 않는다)\n",
    "        파이썬 인터프리터는 그 자체로 GIL(Global Interpreter Lock)이라는 단일(single) lock을 갖는다\n",
    "        GIL은 파이썬에서 한 번에 하나의 스레드만 실행되도록 강제한다\n",
    "'''\n",
    "# def square(x):\n",
    "#     return np.square(x)\n",
    "\n",
    "# 아래의 if문을 사용하지 않으면 무한 오류에 빠지게 된다\n",
    "# 쥬피터에서는 아래의 if문을 사용해도 멀티 프로세싱이 수행되지 않는다\n",
    "if __name__ == \"__main__\":\n",
    "    x = np.arange(64) # 0 ~ 63까지의 정수 생성\n",
    "    print(x, type(x), x.dtype)\n",
    "    print(\"Current Host System cpu core number :\", mp.cpu_count()) # 현재 호스트 시스템의 cpu(코어) 개수를 반환한다\n",
    "                                                                   # 그러나 이것이 현재 프로세스가 사용 가능한 cpu(코어)의 개수를 의미하지는 않는다\n",
    "    pool = mp.Pool(8) # 8개의 프로세스를 가지는 프로세스 풀을 생성한다\n",
    "    squared = pool.map(square, [x[8*i:8*i+8] for i in range(8)]) # 총 64개의 숫자를 8개씩 분할하여 각 프로세스에 배정한다\n",
    "    print(squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b4ba6ab-13b4-4a48-aa5a-9805e92711a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63] <class 'numpy.ndarray'> int32\n",
      "Current Host System cpu core number : 16\n",
      "[ 0  1  4  9 16 25 36 49]\n",
      "[ 64  81 100 121 144 169 196 225]\n",
      "[256 289 324 361 400 441 484 529]\n",
      "[576 625 676 729 784 841 900 961]\n",
      "[1024 1089 1156 1225 1296 1369 1444 1521]\n",
      "[1600 1681 1764 1849 1936 2025 2116 2209]\n",
      "[2304 2401 2500 2601 2704 2809 2916 3025]\n",
      "[3136 3249 3364 3481 3600 3721 3844 3969]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "from lib.worker_testing import square\n",
    "\n",
    "x = np.arange(64) # 0 ~ 63까지의 정수 생성\n",
    "print(x, type(x), x.dtype)\n",
    "print(\"Current Host System cpu core number :\", mp.cpu_count()) # 현재 호스트 시스템의 cpu(코어) 개수를 반환한다\n",
    "                                                               # 그러나 이것이 현재 프로세스가 사용 가능한 cpu(코어)의 개수를 의미하지는 않는다\n",
    "# with 구문을 사용하지 않아도 코드 실행에 아무런 문제는 없지만,\n",
    "# with을 사용하는 것이 자원 관리 측면에서 훨씬 더 좋다\n",
    "with mp.Pool(8) as pool:\n",
    "    squared = pool.map(square, [x[8*i:8*i+8] for i in range(8)]) # 총 64개의 숫자를 8개씩 분할하여 각 프로세스에 배정한다\n",
    "                                                                 # 각 프로세스가 수행해야 하는 작업(함수)과 작업물(데이터)을 명시한다\n",
    "for i in range(len(squared)):\n",
    "    print(squared[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dae53431-4cf0-438e-87b9-b6e3d7fb405a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current available Host System cpu core number : 16\n",
      "[256 289 324 361 400 441 484 529]\n",
      "[ 0  1  4  9 16 25 36 49]\n",
      "[1024 1089 1156 1225 1296 1369 1444 1521]\n",
      "[ 64  81 100 121 144 169 196 225]\n",
      "[1600 1681 1764 1849 1936 2025 2116 2209]\n",
      "[576 625 676 729 784 841 900 961]\n",
      "[2304 2401 2500 2601 2704 2809 2916 3025]\n",
      "[3136 3249 3364 3481 3600 3721 3844 3969]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from lib.worker_testing import square2\n",
    "\n",
    "processes = [] # 프로세스 풀 생성\n",
    "queue = mp.Queue() # 프로세스가 반환하는 결과물을 취합하기 위한 큐 생성\n",
    "x = np.arange(64)\n",
    "\n",
    "print(\"Current available Host System cpu core number :\", mp.cpu_count())\n",
    "\n",
    "# mp.Pool()은 어떤 프로세스에게 어떤 작업을 배정할지를 자동으로 결정하는 반면,\n",
    "# mp.Process()는 어떤 프로세스에게 어떤 작업을 배정할지를 수동으로 지정한다\n",
    "# 프로세스 작업 수행 과정은 CMD에서 확인할 수 있다(.run() 메서드를 사용하면 직접 출력해 볼 수 있다)\n",
    "for i in range(8):\n",
    "    start_index = 8 * i\n",
    "    # multiprocessing에서 process는 Process 객체가 생성되고 이 객체의 start() 메서드가 호출되었을 때 소환된다(spawn)\n",
    "    # Process 객체는 분리된 프로세스 내에서 실행중인 활동을 나타낸다\n",
    "    proc = mp.Process(target=square2, args=(i, x[start_index:start_index+8], queue)) # 프로세스 번호, 작업물, 결과물 저장 큐를 넘겨준다\n",
    "    # proc.run() # 프로세스의 활동을 출력한다\n",
    "                 # 이 메서드를 사용하지 않으면 (쥬피터의 경우) CMD에 프로세스 활동이 출력된다\n",
    "    proc.start() # 프로세스를 시작한다(프로세스가 실제로 생성된다)\n",
    "    processes.append(proc) # 추후 프로세스들을 제어하기 위해 프로세스들을 추적한다\n",
    "\n",
    "for proc in processes:\n",
    "    proc.join() # 프로세스가 종료될 때까지 기다린다\n",
    "                # 좀비 프로세스가 생성되는 것을 막기 위해 가급적이면 .join() 을 사용해서 프로세스를 종료시키는 것이 좋다\n",
    "\n",
    "for proc in processes:\n",
    "    proc.terminate() # 프로세스를 종료한다(자원 반환은 수행하지 않는다)\n",
    "                     # 부모 프로세스를 종료하더라도 그 밑의 자식 프로세스들은 종료되지 않는다(이 경우 자식 프로세스들은 \"기아\"가 된다)\n",
    "\n",
    "for proc in processes:\n",
    "    proc.close() # 프로세스 객체를 해체하여 그것과 관련된 모든 자원들을 반환한다\n",
    "\n",
    "results = []\n",
    "while not queue.empty(): # 큐가 비어있지 않을 경우, 큐 안의 결과물을 반환한다\n",
    "    results.append(queue.get())\n",
    "\n",
    "for i in range(len(results)):\n",
    "    print(results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "434dc884-e345-4c21-b194-3138c5de1c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1's gradient :  tensor([[ 0.1195, -0.1200, -0.2111,  0.0630,  0.1049,  0.0318, -0.0020, -0.0011,\n",
      "          0.0909,  0.1271],\n",
      "        [ 0.0288, -0.0289, -0.0508,  0.0152,  0.0253,  0.0076, -0.0005, -0.0003,\n",
      "          0.0219,  0.0306],\n",
      "        [-0.1314,  0.1320,  0.2321, -0.0692, -0.1154, -0.0349,  0.0022,  0.0012,\n",
      "         -0.0999, -0.1398],\n",
      "        [ 0.1182, -0.1187, -0.2088,  0.0623,  0.1038,  0.0314, -0.0020, -0.0011,\n",
      "          0.0899,  0.1258],\n",
      "        [ 0.1106, -0.1111, -0.1953,  0.0583,  0.0971,  0.0294, -0.0019, -0.0010,\n",
      "          0.0841,  0.1176],\n",
      "        [ 0.0527, -0.0529, -0.0931,  0.0278,  0.0463,  0.0140, -0.0009, -0.0005,\n",
      "          0.0401,  0.0560],\n",
      "        [-0.0833,  0.0836,  0.1470, -0.0439, -0.0731, -0.0221,  0.0014,  0.0008,\n",
      "         -0.0633, -0.0886],\n",
      "        [ 0.0431, -0.0433, -0.0761,  0.0227,  0.0378,  0.0114, -0.0007, -0.0004,\n",
      "          0.0328,  0.0458],\n",
      "        [-0.0648,  0.0651,  0.1144, -0.0341, -0.0569, -0.0172,  0.0011,  0.0006,\n",
      "         -0.0493, -0.0689],\n",
      "        [-0.0281,  0.0283,  0.0497, -0.0148, -0.0247, -0.0075,  0.0005,  0.0003,\n",
      "         -0.0214, -0.0299]])\n",
      "med_out's gradient :  tensor([[-0.2588,  0.0985,  0.0975,  0.0912, -0.1150, -0.0795,  0.1621,  0.0602,\n",
      "         -0.0423,  0.0188],\n",
      "        [-0.2588,  0.0985,  0.0975,  0.0912, -0.1150, -0.0795,  0.1621,  0.0602,\n",
      "         -0.0423,  0.0188],\n",
      "        [-0.2588,  0.0985,  0.0975,  0.0912, -0.1150, -0.0795,  0.1621,  0.0602,\n",
      "         -0.0423,  0.0188],\n",
      "        [-0.2588,  0.0985,  0.0975,  0.0912, -0.1150, -0.0795,  0.1621,  0.0602,\n",
      "         -0.0423,  0.0188]])\n",
      "layer2's gradient :  tensor([[-0.1035,  0.0394,  0.0390,  0.0365, -0.0460, -0.0318,  0.0648,  0.0241,\n",
      "         -0.0169,  0.0075],\n",
      "        [-0.1035,  0.0394,  0.0390,  0.0365, -0.0460, -0.0318,  0.0648,  0.0241,\n",
      "         -0.0169,  0.0075],\n",
      "        [-0.1035,  0.0394,  0.0390,  0.0365, -0.0460, -0.0318,  0.0648,  0.0241,\n",
      "         -0.0169,  0.0075],\n",
      "        [-0.1035,  0.0394,  0.0390,  0.0365, -0.0460, -0.0318,  0.0648,  0.0241,\n",
      "         -0.0169,  0.0075],\n",
      "        [-0.1035,  0.0394,  0.0390,  0.0365, -0.0460, -0.0318,  0.0648,  0.0241,\n",
      "         -0.0169,  0.0075],\n",
      "        [-0.1035,  0.0394,  0.0390,  0.0365, -0.0460, -0.0318,  0.0648,  0.0241,\n",
      "         -0.0169,  0.0075],\n",
      "        [-0.1035,  0.0394,  0.0390,  0.0365, -0.0460, -0.0318,  0.0648,  0.0241,\n",
      "         -0.0169,  0.0075],\n",
      "        [-0.1035,  0.0394,  0.0390,  0.0365, -0.0460, -0.0318,  0.0648,  0.0241,\n",
      "         -0.0169,  0.0075],\n",
      "        [-0.1035,  0.0394,  0.0390,  0.0365, -0.0460, -0.0318,  0.0648,  0.0241,\n",
      "         -0.0169,  0.0075],\n",
      "        [-0.1035,  0.0394,  0.0390,  0.0365, -0.0460, -0.0318,  0.0648,  0.0241,\n",
      "         -0.0169,  0.0075]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "''' \n",
    "    < 실험 결과 >\n",
    "    - layer2 계층에서 도출된 출력으로 손실을 계산하여 역전파를 수행했을 경우\n",
    "    ==> layer2 계층에 대한 기울기만 계산된다\n",
    "    - med_out 계층에서 도출된 출력으로 손실을 계산하여 역전파를 수행했을 경우\n",
    "    ==> med_out과 layer1 계층에 대한 기울기만 계산된다\n",
    "    - layer2와 med_out 계층에서 도출된 출력으로 각각 손실을 계산하여 합산한 후 역전파를 수행했을 경우\n",
    "    ==> 모든 계층에 대한 기울기가 계산된다\n",
    "'''\n",
    "class TestModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(10, 10)\n",
    "        self.med_out = nn.Linear(10, 4)\n",
    "        self.layer2 = nn.Linear(10, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = self.layer1(x)\n",
    "        out2 = self.med_out(out1)\n",
    "        out3 = self.layer2(out1.detach())\n",
    "        return out2, out3\n",
    "    \n",
    "model = TestModel()\n",
    "\n",
    "x = torch.randn(1, 10)\n",
    "# a = model(x)[0]\n",
    "# a = model(x)[1]\n",
    "# a.mean().backward()\n",
    "a, b = model(x)\n",
    "total = a.mean() + b.mean()\n",
    "total.backward()\n",
    "print(\"layer1's gradient : \", model.layer1.weight.grad)\n",
    "print(\"med_out's gradient : \",model.med_out.weight.grad)\n",
    "print(\"layer2's gradient : \",model.layer2.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a2ac89-9774-4080-b994-b209103a01c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' F.normalize() 작동 방식 실험 1 '''\n",
    "\n",
    "b = torch.randn(2, 5)\n",
    "l2_norm_b = b[0].pow(2).sum(dim=0).sqrt()\n",
    "print(\"b:\", b)\n",
    "# print(b[0].pow(2))\n",
    "# print(b[0].pow(2).sum(dim=0))\n",
    "print(\"b[0]'s l2 norm1:\", b[0].pow(2).sum(dim=0).sqrt()) # l2 norm\n",
    "print(\"b[0]'s l2 norm2:\",b[0].norm(p=2))\n",
    "print(\"b's l2 norm for dim=0:\", b.norm(p=2, dim=0)) # dim=0는 열벡터를 대상으로 l2-norm을 계산한다\n",
    "                                                    # 정확히는 dim=0를 구성하는 원소들로 (열)벡터를 만들고, 그것들 각각에 대하여 l2-norm을 계산한다\n",
    "print(\"b's l2 norm for dim=1:\", b.norm(p=2, dim=1)) # dim=1은 행벡터를 대상으로 l2-norm을 계산한다\n",
    "                                                    # 정확히는 dim=1를 구성하는 원소들로 (열)벡터를 만들고, 그것들 각각에 대하여 l2-norm을 계산한다\n",
    "print(\"result:\", b[0] / l2_norm_b)\n",
    "print(F.normalize(b, dim=0)) # dim=0는 열벡터를 대상으로 l2-norm을 구한 후, 그것으로 해당 열벡터를 나누어준다\n",
    "                             # 정확히는 dim=0를 구성하는 원소들로 열벡터를 만들어 그것들 각각에 대해 l2-norm을 계산한 후, 그 결과를 그것에 대응하는 열벡터에 나눠준다\n",
    "print(F.normalize(b, dim=1)) # dim=1는 행벡터를 대상으로 l2-norm을 구한 후, 그것으로 해당 열벡터를 나누어준다\n",
    "                             # 정확히는 dim=1를 구성하는 원소들로 열벡터를 만들어 그것들 각각에 대해 l2-norm을 계산한 후, 그 결과를 그것에 대응하는 열벡터에 나눠준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22d5530-a045-4c5e-a1a5-48b9253c672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' F.normalize() 작동 방식 실험 2 '''\n",
    "\n",
    "(b[0][0])**2 + (b[1][0])**2, ((b[0][0])**2 + (b[1][0])**2).sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65185bb-4e39-4b00-a1b8-e4a435b99ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' F.normalize() 작동 방식 실험 3 '''\n",
    "\n",
    "temp = ((b[0][0])**2 + (b[1][0])**2).sqrt()\n",
    "b[:,0], b[:,0] / temp, F.normalize(b, dim=1), b[0] / b[0].norm(p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5526cd2-dad8-40ec-97fb-0dd6a8d34e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import gymnasium as gym\n",
    "import lock\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(4, 25)\n",
    "        self.l2 = nn.Linear(25, 50)\n",
    "        self.actor_lin1 = nn.Linear(50, 2)\n",
    "        self.l3 = nn.Linear(50, 25)\n",
    "        self.critic_lin1 = nn.Linear(25, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.normalize(x, dim=0) # F.normalize()에서 도출되는 결과의 범위는 [-1.0, 1.0]이다\n",
    "        y = F.relu(self.l1(x))\n",
    "        y = F.relu(self.l1(y))\n",
    "        actor = F.log_softmax(self.actor_lin1(y), dim=0) # 음의 로그 확률 값을 모델 단에서 미리 계산한다(정확히는 그냥 로그 확률이다)\n",
    "        c = F.relu(self.l3(y.detach())) # 여기서 계산 그래프가 분리된다\n",
    "        critic = torch.tanh(self.critic_lin1(c)) # 가치 함수 값을 tanh을 사용하여 [-1.0, 1.0] 구간의 값으로 변환시켜준 것은\n",
    "                                                 # 이익 계산에서의 Returns를 정규화하여 [-1.0, 1.0] 구간의 값으로 변환하기 때문이다\n",
    "        return actor, critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b21e73c-148b-499e-9432-d936f4ee69ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 이 코드 블럭의 코드들은 모두 worker.py에 기입되었으며 쥬피터 셸 상에서는 실행하지 않는다 '''\n",
    "\n",
    "def worker(t, worker_model, counter, params, lock):\n",
    "    worker_env = gym.make(\"CartPole-v1\") # 환경 불러오기\n",
    "    worker_opt = optim.Adam(lr=1e-4, params=worker_model.parameters())\n",
    "\n",
    "    for i in range(params[\"epochs\"]):\n",
    "        state_values, logprobs, rewards = run_episode(worker_env, worker_model)\n",
    "        actor_loss, critic_loss, ep_len = update_params(worker_opt, state_values, logprobs, rewards)\n",
    "        with lock:\n",
    "            counter.value = counter.value + 1\n",
    "\n",
    "def run_episode(worker_env, worker_model):\n",
    "    cur_state = torch.from_numpy(worker_env.reset()[0]).float()\n",
    "    state_values, logprobs, rewards = [], [], []\n",
    "    done = False # 에피소드 종료 여부\n",
    "\n",
    "    while (done == False):\n",
    "        policy, state_value = worker_model(cur_state)\n",
    "        state_values.append(state_value)\n",
    "        logits = policy.view(-1) # 1차원 텐서로 변환한다\n",
    "        action_dist = torch.ditributions.Categorical(logtis=logits) # 카테고리컬 분포는 시행 횟수 n이 1인 다항분포와 동일한 분포이다\n",
    "                                                                    # 여기서의 역할은 주어진 로짓을 확률분포로 변환하여 이 확률분포를 토대로 표본을 추출할 수 있도록 하는 것이다\n",
    "        action = action_dist.sample()\n",
    "        logprob_ = logits[action]\n",
    "        logprobs.append(logprob_)\n",
    "        next_state, _, done, _, _ = woker_env.step(action.numpy())\n",
    "        cur_state = torh.from_numpy(next_state).float()\n",
    "        if done:\n",
    "            reward = -10\n",
    "            worker_env.reset()\n",
    "        else:\n",
    "            reward = 1.0\n",
    "        rewards.append(reward)\n",
    "\n",
    "    return state_values, logprobs, rewards\n",
    "\n",
    "def update_params(worker_opt, state_values, logprobs, rewards, clc=0.1, gamma=0.95):\n",
    "    rewards = torch.tensor(rewards).flip(dim=(0,)).view(-1)\n",
    "    logprobs = torch.stack(logprobs).flip(dims=(0,)).view(-1) # torch.stack 대신 torch.tensor를 사용해도 된다\n",
    "    state_values = torch.stack(values).flip(dims=(0,)).view(-1) # torch.stack 대신 torch.tensor를 사용해도 된다\n",
    "    Returns = [] # 반환값 저장\n",
    "    ret_ = torch.tensor([0])\n",
    "    for r in range(rewards.shape[0]): # 보상의 개수만큼 반복을 수행한다\n",
    "        ret_ = rewards[r] + gamma * ret_ # 에피소드의 마지막 타임 스텝부터 반환값을 계산한다\n",
    "        Returns.append(ret_)\n",
    "\n",
    "    Returns = torch.stack(Returns).view(-1) # 텐서가 원소인 리스트를 torch.tensor를 통해 텐서로 변환하면 오류가 발생하는데, torch.stack을 사용하면 오류없이 텐서로 변환할 수 있다\n",
    "    Returns = F.normalize(Returns, dim=0) # 반환값들에 대해 정규화를 수행하여 [-1.0, 1.0] 구간의 값으로 변환한다\n",
    "                                          # 이것때문에 비평자의 출력에 tanh를 적용한 것이다\n",
    "    actor_loss = -1 * logprobs * (Returns - values.detach())\n",
    "    critic_loss = torch.pow(values - Returns, 2)\n",
    "    loss = actor_loss.sum() + clc * critic_loss.sum() # 행위자가 비평자보다 더 빨리 학습하도록 하기 위해 clc=0.1을 곱한다\n",
    "                                                      # 비평자의 전체 손실 중 일부로만 역전파를 수행하여 비평자의 학습을 지연시킨다\n",
    "    # 역전파 수행\n",
    "    worker_opt.zero_grad()\n",
    "    loss.backward()\n",
    "    worker_opt.step()\n",
    "\n",
    "    return actor_loss, critic_loss, len(rewards) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afcad117-7148-4bac-8ef0-6cfa39db48aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1792576605.py, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 25\u001b[1;36m\u001b[0m\n\u001b[1;33m    https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Value\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "''' 모델 학습 '''\n",
    "\n",
    "MasterNode = ActorCritic()\n",
    "MasterNode.share_memory() # share_memory() 메서드는 이를 호출한 텐서를 shared_memory로 이동시킨다\n",
    "                           # 여기서는 shared_memory에 모델의(여기서는 ActorCritic()) 매개변수를 저장하여,\n",
    "                           # 서로의 모델을 훈련시키려는 각 프로세스가 동일한 모델 매개변수를 공유하도록 한다\n",
    "processes = []\n",
    "params = {\n",
    "    \"epochs\":1000,\n",
    "    \"n_workers\":7\n",
    "}\n",
    "\n",
    "'''\n",
    "    참고 : https://devocean.sk.com/blog/techBoardDetail.do?ID=163669\n",
    "         : https://stackoverflow.com/questions/74635994/pytorchs-share-memory-vs-built-in-pythons-shared-memory-why-in-pytorch-we\n",
    "         : https://realpython.com/python-gil/\n",
    "         : https://stackoverflow.com/questions/74635994/pytorchs-share-memory-vs-built-in-pythons-shared-memory-why-in-pytorch-we\n",
    "'''\n",
    "'''\n",
    "    파이썬에서 생성되는 모든 객체들은 reference count variable(이하 참조 횟수 변수라 칭한다)를 갖는다\n",
    "    이는 해당 객체를 가리키는 참조자들의 수를 추적하여 메모리 관리를 하기 위함이다\n",
    "    참조 횟수가 0에 다다르면(참조 횟수 변수가 0값을 가지게 되면) 해당 객체가 차지하고 있는 메모리는 반환된다(즉, 객체가 소멸된다)\n",
    "    이렇듯 참조 횟수 변수는 매우 중요하기 때문에 정확히 추적되어야 하는데, 이를 위해 스레드 간 공유되는 모든 데이터 구조체들(객체)에 lock을 추가할 수 있다\n",
    "    하지만 (공유되는) 각각의 객체에 모두 lock을 추가한다는 것은 deadlock(교착 상태)을 야기할 수 있는 다중 lock 현상이 발생할 수 있다는 것을 의미한다\n",
    "    따라서 파이썬에서는 이를 해결하고자 단일 lock인 GIL을 도입하여 한번에 하나의 스레드만 실행할 수 있도록 만들었다\n",
    "    즉, 한 번에 하나의 스레드만 자원을 선점할 수 있게 강제한 것이다(최종적으로 lock 1개만 존재하는 셈이 된다)\n",
    "    GIL 덕분에 단일 스레드 프로그램은 그로 인한 성능상 혜택을 누릴 수 있지만, 다중 스레드 프로그램은 그렇지 못하고 되려 성능 저하가 발생한다\n",
    "    CPU 중심 다중 스레드 프로그램의 경우 특히나 GIL로 인해 병렬 처리가 불가능해 작업 처리 지연으로 인한 성능 저하가 심하다\n",
    "    반면, I/O 중심 다중 스레드 프로그램의 경우 요청한 I/O 처리를 대기하는 데에 상당한 시간을 소비하므로(이 때 동안은 작업을 처리하지 않는다) 스레들끼리 GIL을 번갈아 가며 공유하는 형식이 되어 성능 저하가 거의 발생하지 않는다\n",
    "    GIL로 인한 성능 저하를 해결하기 위해 다중 프로세싱을 사용할 수 있다\n",
    "    다중 프로세싱을 사용하더라도 작업 처리 시간이 그에 비례하여 줄어드는 것은 아닌데, 이는 프로세스 관리 자체에 overhead(추가 비용)가 존재하기 때문이다\n",
    "    다중 프로세스는 다중 스레드보다 훨씬 더 무거운 작업이기 때문에 규모를 키우면 병목 현상이 발생하게 된다는 점을 명심해야 한다\n",
    "'''\n",
    "'''\n",
    "    python 내장 모듈인 multiprocessing이 공유 메모리(shared_memory)를 다루는 방법은 아래와 같다\n",
    "    1. 공유 메모리로부터 공유 객체를 생성한다\n",
    "    2. 자식 프로세스와 공유 객체를 공유할 때는 공유 메모리의 이름, 공유 객체의 데이터 크기(혹은 shape) 및 자료형을 serialize하여 전달한다\n",
    "    3. 자식 프로세스는 전달받은 것을 deserialize한 후, 이를 바탕으로 다시 공유 메모리로부터 공유 객체를 복원하여 사용한다\n",
    "    4. 공유 객체에 대한 변형은 그대로 공유 메모리에 반영되므로, 모든 프로세스가 동일한 영향을 받게 된다\n",
    "'''\n",
    "'''\n",
    "    여기서의 mp.Value는 python의 multiprocessing 모듈에 존재하는 클래스이다\n",
    "    torch.multiprocessing이 python 내장 모듈인 multiprocessing의 warraper이자 100% 호환되기 때문에 torch.multiprocessing에서도 mp.Value를 사용할 수 있는 것이다\n",
    "    공유 메모리(shared memory)로부터 할당된(생성된) ctypes(C언어와 호환되는 자료형이다) 객체를 반환한다\n",
    "    기본적으로 mp.Value로 반환된 값은 실제로는 공유 메모리로부터 생성된 ctypes 객체에 대한 동기화된 wrapper이다(당연하게도 이 역시 객체이다)\n",
    "    생성된 ctypes 객체 자체는 mp.Value에서 반환된 객체(wrapper)의 value 속성을 통해 접근할 수 있다\n",
    "    \"i\"는 typecode_or_type의 인자로, 이것은 반환되는 객체의 자료형을 결정한다\n",
    "    typecode_or_type은 ctypes 형이나 또는 array 모듈에서 사용되는 종류의 단일 문자 typecode가 될 수 있다\n",
    "    \"+=\"와 같이 읽기와 쓰기를 함께 수반하는 연산들은 \"원자적(atomic) 연산\"을 지원하지 않는다\n",
    "    원자적 연산이란 여러 스레드 또는 프로세스에서 동시에 특정 데이터에 접근해도 데이터의 일관성을 보장하는 연산을 말한다\n",
    "    따라서 공유 객체에 대해 증감 연산 같은 연산을 수행하고 싶다면, 해당 공유 객체를 선점하고 반환하는 과정을 반드시 명시해야 한다\n",
    "'''\n",
    "counter = mp.Value(\"i\", 0)\n",
    "lock = mp.Lock() # 프로세스들이 공유 객체를 사용함에 있어 서로 간섭하지 못하도록 lock을 통해 우선 선점 후 사용하도록 한다\n",
    "\n",
    "for i in range(params[\"n_workers\"]):\n",
    "    p = mp.Process(target=worker, args=(i, MasterNode, counter, params, lock)) # args는 프로세스에게 할당할 작업의 인자를 의미한다\n",
    "    p.start() # 프로세스가 실제로 생성된다\n",
    "    processes.append(p)\n",
    "\n",
    "for p in processes:\n",
    "    p.join() # 프로세스가 종료될 때 까지 block시킨다\n",
    "             # join() 메서드를 사용하지 않으면 자식 프로세스는 유휴상태(idle)에 들어가고 종료되지 않아(부모 프로세스는 종료된다) 좀비 프로세스가 되어 손수 kill해줘야만 소멸하게 된다\n",
    "             # 즉, join() 메서드가 하는 일은 부모 프로세스가 자식 프로세스보다 먼저 종료되지 못하도록 막는다\n",
    "\n",
    "for p in processes:\n",
    "    p.terminate() # 프로세스를 종료한다\n",
    "                  # 부모 프로세스는 terminate() 메서드를 사용하지 않아도 자동으로 종료된다(하지만 자식 프로세스는 자동으로 종료되지 않는다)\n",
    "\n",
    "print(counter.value, processes[1].exitcode) # 공유 객체에 저장된 값을 출력한다\n",
    "                                            # .exitcode는 자식 프로세스의 종료 코드(exit code)이다\n",
    "                                            # 자식 프로세스가 아직 종료되지 않았다면 \"None\"을 반환하고,\n",
    "                                            # 정상적으로 종료되었다면 \"0\"을 반환한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef5ba59-966a-4d28-9a73-e8863eb20fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 학습 후 시험(test) '''\n",
    "\n",
    "env = gym.make(\"CartPole-v1\") # 카트폴 환경 불러오기\n",
    "\n",
    "for i in range(100):\n",
    "    cur_state = torch.from_numpy(env.reset()[0]).float() # 환경 초기화 및 초기 상태 반환\n",
    "    logits, value = MasterNode(cur_state)\n",
    "    action_dist = torch.distributions.Categorical(logits=logits) # 옆의 코드는 카테고리컬 분포 말고 다항 분포로도 구현할 수 있다\n",
    "    action = action_dist.sample() # logit에 근거한 확률분포를 바탕으로 2개의 행동 중 하나를 뽑는다\n",
    "    next_state, reward, done, _, _ = env.step(action.numpy())\n",
    "    if done:\n",
    "        print(\"Lost\")\n",
    "        cur_state = torch.from_numpy(env.reset()[0]).flot()\n",
    "    env.render() # 에이전트가 현재 보고 있는 것의 시각화를 위해 환경을 렌더링 한다\n",
    "                 # 이전에는 render() 메서드가 인자를 받았지만, 지금은 이 인자를 make() 메서드가 받도록 수정되었다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d782cdcb-c7ab-48ae-9901-20befd3c183c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03231152 -0.00984595 -0.02659299  0.00150169] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "temp = env.reset()\n",
    "print(temp[0], type(temp[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
